{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import  sys\n",
    "sys.path.insert(0, \"d:\\python\\diabolo\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import scipy\n",
    "import platform\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,average_precision_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import sklearn.metrics \n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version is........... 3.6.5\n",
      "scikit-learn version is..... 0.19.1\n",
      "pandas version is........... 0.22.0\n",
      "numpy version is............ 1.14.2\n",
      "matplotlib version is....... 2.2.0\n",
      "scipy version is....... 1.0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Python version is........... %s.%s.%s\" % sys.version_info[:3])\n",
    "print('scikit-learn version is.....', sklearn.__version__)\n",
    "print('pandas version is...........', pd.__version__)\n",
    "print('numpy version is............', np.__version__)\n",
    "print('matplotlib version is.......', matplotlib.__version__)\n",
    "print('scipy version is.......', scipy.__version__)\n",
    "\n",
    "def my_drop(df, col):\n",
    "\n",
    "    if col in df:\n",
    "        df.drop([col], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def assign_selection(W):\n",
    "    if W <4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCEDURE DE BASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_mymodel(clf,allure):\n",
    "    joblib.dump(clf,'diabolo'+str(allure)+'.pkl')\n",
    "\n",
    "\n",
    "def load_mymodel(allure):\n",
    "    clf=joblib.load('diabolo'+str(allure)+'.pkl')\n",
    "    return clf\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.start = time.time()\n",
    "\n",
    "    def restart(self):\n",
    "        self.start = time.time()\n",
    "\n",
    "    def get_time(self):\n",
    "        end = time.time()\n",
    "        m, s = divmod(end - self.start, 60)\n",
    "        h, m = divmod(m, 60)\n",
    "        time_str = \"%02d:%02d:%02d\" % (h, m, s)\n",
    "        return time_str\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définir une méthode pour tracer l'importance du prédicteur\n",
    "def Plot_predictor_importance(best_model, feature_columns):\n",
    "    feature_importance = best_model.feature_importances_\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    y_pos  = np.arange(sorted_idx.shape[0]) + .7\n",
    "    fig, ax = plt.subplots( figsize=(10, 10))\n",
    "\n",
    "\n",
    "\n",
    "    ax.barh(y_pos,\n",
    "            feature_importance[sorted_idx],\n",
    "            align='center',\n",
    "            color='green',\n",
    "            ecolor='black',\n",
    "            height=0.8)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(feature_columns)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "\n",
    "\n",
    "    ax.set_xlabel('Relative Importance')\n",
    "    ax.set_title('Predictor Importance')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construireFichierCSV(allure, best_model, feature_columns, response_column, mode_debug=0):\n",
    "    # lecture des données a jouer\n",
    "\n",
    "\n",
    "    xnames = ['ALLURE', 'CO_DISTANCE',\n",
    "              'CO_PRIX', 'HIPPO',\n",
    "              'IDCOURSE', 'IDPARTCIPANT',\n",
    "              'PAR_AGE', 'PAR_ARRIVE',\n",
    "              'PAR_CARRIERE',\n",
    "              'PAR_CARRIERE_Q',\n",
    "              'PAR_CLASSE_AGE',\n",
    "              'PAR_COTEDER',\n",
    "              'PAR_ENT_ECART_GAGNANT',\n",
    "              'PAR_ENT_RAPPORT_GAGNANT_M',\n",
    "              'PAR_ENT_REU_PLACE',\n",
    "              'PAR_ENT_REUSSITE_GAGNE',\n",
    "              'PAR_ENT_VICTOIRE',\n",
    "              'PAR_GAIN',\n",
    "              'pAR_JOC_ECART_GAGNANT',\n",
    "              'PAR_JOC_ECART_PLACE',\n",
    "              'PAR_JOC_NB_COURSE',\n",
    "              'PAR_JOC_PLACE_3P',\n",
    "              'pAR_JOC_RAPPORT_GAGNANT_M',\n",
    "              'PAR_JOC_REU_PLACE',\n",
    "              'pAR_JOC_REUSSITE_GAGNE',\n",
    "              'pAR_JOC_VICTOIRE',\n",
    "              'PAR_NP',\n",
    "              'PAR_NUM',\n",
    "              'PAR_PLACE',\n",
    "              'PAR_PLACE_Q',\n",
    "              'PAR_REUSSITE_3P',\n",
    "              'PAR_REUSSITE_GAGNE',\n",
    "              'PAR_REUSSITE_QUINTE',\n",
    "              'PAR_RUESSITE_PLACE',\n",
    "              'autostart',\n",
    "              'cendre',\n",
    "              'grande_piste',\n",
    "              'Point',\n",
    "              'Nb_partant', 'PAR_PROPRIO',\n",
    "              'NOM_JOC',\n",
    "              'NOM_ENTR',\n",
    "              'POIDS',\n",
    "              'CORDE',\n",
    "              'CHEVAL',\n",
    "              'FIN_ligne']\n",
    "\n",
    "\n",
    "\n",
    "    df_numero_a_predire = lecture_data.lecture_data('d:\\diabollo_al_1_D.csv', xnames, ['IDPARTCIPANT', 'IDCOURSE'],allure=allure)\n",
    "\n",
    "\n",
    "\n",
    "    if allure==5:\n",
    "        print(\"\\nSHAPE Numero a predire\")\n",
    "        print(df_numero_a_predire.shape)\n",
    "\n",
    "\n",
    "\n",
    "    df_numero_a_predire = df_numero_a_predire.groupby(\"ALLURE\")\n",
    "    df_numero_a_predire = df_numero_a_predire.get_group(allure)\n",
    "    df_numero_a_predire = lecture_data.my_drop(df_numero_a_predire, 'ALLURE')\n",
    "\n",
    "    df_numero_a_predire = lecture_data.my_drop(df_numero_a_predire, 'PAR_ARRIVE')\n",
    "\n",
    "    if mode_debug == 1:\n",
    "        print(\"\\nSHAPE Numero a predire\")\n",
    "        print(df_numero_a_predire.shape)\n",
    "\n",
    "    my_timer = analyse.Timer()\n",
    "\n",
    "\n",
    "    df_numero_a_predire['SELECTION'] = 0\n",
    "\n",
    "    train_x, test_x, train_y, test_y = analyse.split_dataset(df_numero_a_predire, 0, feature_columns, response_column)\n",
    "   # print(test_x.head(2))\n",
    "    print(test_x.shape)\n",
    "\n",
    "\n",
    "    # sauvegarde\n",
    "    y_pred = best_model.predict(test_x)\n",
    "    if mode_debug == 1:\n",
    "        print(\"y pred\")\n",
    "        print(y_pred)\n",
    "\n",
    "    df_pred = pd.DataFrame.from_dict(y_pred)\n",
    "    test_copy = test_x.copy()\n",
    "\n",
    "\n",
    "\n",
    "    # print(df_pred)\n",
    "    #print(\"PREDICTION COURSES A JOUER\")\n",
    "    if mode_debug==1:\n",
    "        print(y_pred)\n",
    "\n",
    "\n",
    "    # UTILISATION DE BEST_MODEL\n",
    "    PROBA = best_model.predict_proba(test_x)\n",
    "    #print(\"PROBA \\n %s\" ,PROBA)\n",
    "\n",
    "    df_proba = pd.DataFrame.from_dict(PROBA)\n",
    "\n",
    "    #print(\"df final=\")\n",
    "    df_final = pd.concat([df_proba, df_pred], axis=1)\n",
    "\n",
    "    if mode_debug==1:\n",
    "        print(\"SHAPE df_final\")\n",
    "        print(df_final.shape)\n",
    "\n",
    "\n",
    "    test_x = test_copy.copy()\n",
    "\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_CLASSE_AGE')\n",
    "\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_ENT_ECART_GAGNANT')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_ENT_RAPPORT_GAGNANT_M')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_ENT_REU_PLACE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_ENT_REUSSITE_GAGNE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_ENT_VICTOIRE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_GAIN')\n",
    "    test_x = lecture_data.my_drop(test_x, 'pAR_JOC_ECART_GAGNANT')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_JOC_ECART_PLACE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_JOC_NB_COURSE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_JOC_PLACE_3P')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_REUSSITE_GAGNE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_REUSSITE_QUINTE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_RUESSITE_PLACE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'CO_PRIX')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_CARRIERE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_CARRIERE_Q')\n",
    "    test_x = lecture_data.my_drop(test_x, 'pAR_JOC_RAPPORT_GAGNANT_M')\n",
    "    test_x = lecture_data.my_drop(test_x, 'pAR_JOC_REUSSITE_GAGNE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'pAR_JOC_VICTOIRE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_PLACE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_PLACE_Q')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_CLASSE_AGE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'pAR_JOC_VICTOIRE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_REUSSITE_3P')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_JOC_REU_PLACE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_NUM')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_COTEDER')\n",
    "    test_x = lecture_data.my_drop(test_x, 'CORDE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'musique')\n",
    "    test_x = lecture_data.my_drop(test_x, 'CHEVAL')\n",
    "    test_x = lecture_data.my_drop(test_x, 'Nb_partant')\n",
    "\n",
    "    test_x = lecture_data.my_drop(test_x, 'autostart')\n",
    "    test_x = lecture_data.my_drop(test_x, 'grande_piste')\n",
    "    test_x = lecture_data.my_drop(test_x, 'cendre')\n",
    "\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_PROPRIO')\n",
    "    test_x = lecture_data.my_drop(test_x, 'NOM_JOC')\n",
    "    test_x = lecture_data.my_drop(test_x, 'NOM_ENTR')\n",
    "\n",
    "    test_x = lecture_data.my_drop(test_x, 'HIPPO')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_AGE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'POIDS')\n",
    "    test_x = lecture_data.my_drop(test_x, 'CO_DISTANCE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'CO_PRIX')\n",
    "\n",
    "    #print(\"test_x\",test_x.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #print(test_x)\n",
    "\n",
    "\n",
    "    test_x['v0'] = 0.0\n",
    "    test_x['v1'] = 0.0\n",
    "    test_x['sel'] = 0\n",
    "    #   print(\"test_x\", test_x.shape)\n",
    "    # test_x\n",
    "    cumul = 1\n",
    "    nb_rows = len(df_proba.index)\n",
    "    print(\"nb_rows=\", nb_rows)\n",
    "\n",
    "    for i in range(0, nb_rows):\n",
    "        n = df_proba[0][i]\n",
    "        test_x['v0'][i] = n\n",
    "\n",
    "        n = df_proba[1][i]\n",
    "        test_x['v1'][i] = n\n",
    "\n",
    "\n",
    "    #print(\"test_x\",test_x.shape)\n",
    "\n",
    "   # print(\"\\n\\nTEST_X\\n\")\n",
    "   # print(test_x.head())\n",
    "\n",
    "    if (allure == 1):\n",
    "        test_x.to_csv(\"d:\\py_resultat_trot.csv\")\n",
    "\n",
    "    if (allure == 2):\n",
    "        test_x.to_csv(\"d:\\py_resultat_galop.csv\")\n",
    "\n",
    "    if (allure == 3):\n",
    "        test_x.to_csv(\"d:\\py_resultat_trot_monte.csv\")\n",
    "\n",
    "    if (allure == 4):\n",
    "        test_x.to_csv(\"d:\\py_resultat_haie.csv\")\n",
    "\n",
    "    if (allure == 5):\n",
    "        test_x.to_csv(\"d:\\py_resultat_steeple.csv\")\n",
    "\n",
    "    elapsed = my_timer.get_time()\n",
    "    print(\"\\nTemps de calcul de la construction du fichier  est : %s\" % elapsed)\n",
    "    print(\"\\n\\n ALLER DANS APPLICATION DIABOLO ....\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def lecture_data(Fichier, xnames, xindex_col, allure=1, mode_debug=0,avec_index=True):\n",
    "\n",
    "    \n",
    "\n",
    "    if  avec_index==True:\n",
    "        df = pd.read_csv(Fichier,\n",
    "                     index_col=xindex_col,\n",
    "                     sep=';',\n",
    "                     names=xnames, skipinitialspace=True,\n",
    "                     encoding='Latin-1')\n",
    "    else:\n",
    "        df = pd.read_csv(Fichier,\n",
    "                         index_col=None,\n",
    "                         sep=';',\n",
    "                         names=xnames, skipinitialspace=True,\n",
    "                         encoding='Latin-1')\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nDF Après LECTURE -------------- \",Fichier)\n",
    "\n",
    "    print(\"\\n\",df.shape)\n",
    "#    print(\"\\n\",df.head(5))\n",
    "\n",
    "\n",
    "    if  avec_index==False:\n",
    "        df.drop([\"IDPARTCIPANT\"], axis=1, inplace=True)\n",
    "        df.drop([\"IDCOURSE\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    df.drop([\"FIN_ligne\"], axis=1, inplace=True)\n",
    "    df.drop([\"PAR_NP\"], axis=1, inplace=True)\n",
    "    df.drop([\"cendre\"], axis=1, inplace=True)\n",
    "   # df.drop([\"CO_PRIX\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    df.drop([\"PAR_CLASSE_AGE\"], axis=1, inplace=True)\n",
    "\n",
    "    #df.drop([\"NOM_JOC\"], axis=1, inplace=True)\n",
    "    #df.drop([\"NOM_ENTR\"], axis=1, inplace=True)\n",
    "    #df.drop([\"CHEVAL\"], axis=1, inplace=True)\n",
    "    #df.drop([\"PAR_PROPRIO\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "   #df.drop([\"PAR_AGE\"], axis=1, inplace=True)\n",
    "    df.drop([\"grande_piste\"], axis=1, inplace=True)\n",
    "    #df.drop([\"PAR_COTEDER\"], axis=1, inplace=True)\n",
    "    #df=my_drop(df, \"HIPPO\")\n",
    "    df=my_drop(df, \"PAR_AGE\")\n",
    "    df = my_drop(df, \"PAR_GAIN\")\n",
    "\n",
    "\n",
    "\n",
    "    if allure==1:\n",
    "        df.drop([\"POIDS\"], axis=1, inplace=True)\n",
    "        df.drop([\"CORDE\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    if allure == 2:\n",
    "        df.drop([\"autostart\"], axis=1, inplace=True)\n",
    "        df.drop([\"CO_DISTANCE\"], axis=1, inplace=True)\n",
    "\n",
    "    if allure == 3:\n",
    "        df.drop([\"POIDS\"], axis=1, inplace=True)\n",
    "        df.drop([\"CORDE\"], axis=1, inplace=True)\n",
    "        df.drop([\"autostart\"], axis=1, inplace=True)\n",
    "\n",
    "    if allure == 4:\n",
    "        df.drop([\"autostart\"], axis=1, inplace=True)\n",
    "        df.drop([\"CO_DISTANCE\"], axis=1, inplace=True)\n",
    "        df.drop([\"CORDE\"], axis=1, inplace=True)\n",
    "\n",
    "    if allure == 5:\n",
    "        df.drop([\"autostart\"], axis=1, inplace=True)\n",
    "        df.drop([\"CO_DISTANCE\"], axis=1, inplace=True)\n",
    "        df.drop([\"CORDE\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def calul_data_allure(allure_etudier, mode_debug=0,avec_index=True):\n",
    "\n",
    "    xnames = ['ALLURE'  , 'CO_DISTANCE',\n",
    "              'CO_PRIX',  'HIPPO',\n",
    "              'IDCOURSE', 'IDPARTCIPANT',\n",
    "              'PAR_AGE',      'PAR_ARRIVE',\n",
    "              'PAR_CARRIERE',\n",
    "              'PAR_CARRIERE_Q',\n",
    "              'PAR_CLASSE_AGE',\n",
    "              'PAR_COTEDER',\n",
    "              'PAR_ENT_ECART_GAGNANT',\n",
    "              'PAR_ENT_RAPPORT_GAGNANT_M',\n",
    "              'PAR_ENT_REU_PLACE',\n",
    "              'PAR_ENT_REUSSITE_GAGNE',\n",
    "              'PAR_ENT_VICTOIRE',\n",
    "              'PAR_GAIN',\n",
    "              'pAR_JOC_ECART_GAGNANT',\n",
    "              'PAR_JOC_ECART_PLACE',\n",
    "              'PAR_JOC_NB_COURSE',\n",
    "              'PAR_JOC_PLACE_3P',\n",
    "              'pAR_JOC_RAPPORT_GAGNANT_M',\n",
    "              'PAR_JOC_REU_PLACE',\n",
    "              'pAR_JOC_REUSSITE_GAGNE',\n",
    "              'pAR_JOC_VICTOIRE',\n",
    "              'PAR_NP',\n",
    "              'PAR_NUM',\n",
    "              'PAR_PLACE',\n",
    "              'PAR_PLACE_Q',\n",
    "              'PAR_REUSSITE_3P',\n",
    "              'PAR_REUSSITE_GAGNE',\n",
    "              'PAR_REUSSITE_QUINTE',\n",
    "              'PAR_RUESSITE_PLACE',\n",
    "              'autostart',\n",
    "              'cendre',\n",
    "              'grande_piste',\n",
    "              'Point',\n",
    "              'Nb_partant','PAR_PROPRIO',\n",
    "                                         'NOM_JOC',\n",
    "                                         'NOM_ENTR',\n",
    "                                        'POIDS',\n",
    "                                        'CORDE', 'CHEVAL',\n",
    "                                         'FIN_ligne']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df = lecture_data('d:\\diabollo_al_1.csv', xnames, ['IDPARTCIPANT', 'IDCOURSE'],allure=allure_etudier,avec_index=avec_index)\n",
    "\n",
    "\n",
    "\n",
    "    # groupage par allure\n",
    "    df = df.groupby(\"ALLURE\")\n",
    "    df = df.get_group(allure_etudier)\n",
    "    #df.head(5)\n",
    "    df = my_drop(df, 'ALLURE')\n",
    "    # Contruction de df_gagant\n",
    "    df_gagnant = df\n",
    "    # les lignes sans arrivée n'apportent rien !!!!\n",
    "    df_gagnant = df_gagnant[df_gagnant.PAR_ARRIVE > 0]  # On garde la ligne qui possede information arrivée\n",
    "    #df_gagnant = df_gagnant[df_gagnant.PAR_GAIN < 20000000]\n",
    "    #df_gagnant = df_gagnant[df_gagnant.PAR_GAIN > 0]\n",
    "\n",
    "\n",
    "\n",
    "    if allure_etudier==2:\n",
    "        df_gagnant = df_gagnant[df_gagnant.POIDS > 0]\n",
    "        df_gagnant = df_gagnant[df_gagnant.POIDS < 100]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Shape des données df_gagant\n",
    "    if  mode_debug==1:\n",
    "        print(\" df_gagnant \", df_gagnant.shape)\n",
    "        COLUM = df_gagnant.columns\n",
    "        print(\"Features\", COLUM )\n",
    "\n",
    "    # Construction de la cible\n",
    "    df_gagnant['SELECTION'] = df_gagnant['PAR_ARRIVE'].apply(assign_selection)\n",
    "\n",
    "    #df_gagnant = df_gagnant[df_gagnant.PAR_COTEDER < 150]\n",
    "     # Suppression de la colonne qui a permis de construire la cible : PAR_ARRIVE\n",
    "    df_gagnant.drop([\"PAR_ARRIVE\"], axis=1, inplace=True)\n",
    "\n",
    "    #fig, ax = plt.subplots(figsize=(16, 16))\n",
    "\n",
    "    #sns.heatmap(df_gagnant.corr(), annot=True, fmt=\".1f\", linewidths=.4, ax=ax)\n",
    "    #plt.show(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#    print(\"\\ndf_gagnant \\n\", df_gagnant.shape)  # description de l'ensemble\n",
    " #   pd.DataFrame.hist(df_gagnant, figsize = [18,18])\n",
    "\n",
    "\n",
    "\n",
    "    df_gagnant_len            = len(df_gagnant.columns) - 1\n",
    "    Lib_features                = list(df_gagnant.columns[:df_gagnant_len])  # Liebllé des variable DATA\n",
    "    feature_columns         = Lib_features ##<<<<<<<<<<<<<<<<\n",
    "    n_features = len(feature_columns) ##<<<<<<<<<<<<<<<<\n",
    "    response_column = ['SELECTION']  ##<<<<<<<<<<<<<<<<\n",
    "\n",
    "    print(df_gagnant.shape)  # lignes = observations\n",
    "    print(df_gagnant.dtypes)  # lignes = observations\n",
    "\n",
    "\n",
    "    print(\"Features                   :  \", Lib_features, \" <<<<************\")\n",
    "\n",
    "    print(\"Nombre de feature   :  \", n_features)\n",
    "    print(\"Colonne cible            : \", response_column)\n",
    "    print(\"FEATURES COLONNES            : \", feature_columns)\n",
    "    print(\"\\n\\n------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    return df_gagnant, n_features, feature_columns, response_column\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def donnees_allure(allure, nb_iter,mode_debug=0, actualise=0):\n",
    "    # LECTURE DATA\n",
    "    print('---------------------ALLURE(  %s  )------------------------------------------------' % allure)\n",
    "    # Le fichier est lu meme si on  a le best model\n",
    "    df_gagnant, n_features, feature_columns, response_column =calul_data_allure(allure_etudier = allure,mode_debug=mode_debug)\n",
    "\n",
    "    return df_gagnant, n_features, feature_columns, response_colum\n",
    "\n",
    "\n",
    "\n",
    "def save_mymodel(clf,allure):\n",
    "    joblib.dump(clf,'diabolo'+str(allure)+'.pkl')\n",
    "\n",
    "\n",
    "def load_mymodel(allure):\n",
    "    clf=joblib.load('diabolo'+str(allure)+'.pkl')\n",
    "    return clf\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def afficheEvalSet(mybest_model,\n",
    "                    set_train,\n",
    "                   set_train_cible,\n",
    "                   set_test,\n",
    "                   set_test_cible,\n",
    "                   mode_debug=0,\n",
    "                   type_eval=1):\n",
    "\n",
    "\n",
    "    set_test_cible_predicted = mybest_model.predict(set_test)\n",
    "    set_train_cible_predicted = mybest_model.predict(set_train)\n",
    "\n",
    "    print('Accuracy is: ', mybest_model.score(set_test, set_test_cible))  # accuracy\n",
    "\n",
    "\n",
    "    if type_eval==1:\n",
    "                print(\"Evaluation TEST-----------------------------------------------------------------------\")\n",
    "\n",
    "                set_test_cible_probabilities = mybest_model.predict_proba(set_test)\n",
    "                auc = roc_auc_score(set_test_cible, set_test_cible_predicted)\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "                print(\"Evaluation TRAINING--------------------------------------------------------------------\")\n",
    "\n",
    "                set_train_cible_probabilities = mybest_model.predict_proba(set_train)\n",
    "                auc = roc_auc_score(set_train_cible, set_train_cible_predicted)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n roc_auc_score :  \", auc)\n",
    "    \n",
    "    for x, y in [(set_train, set_train_cible), (set_test, set_test_cible)]:\n",
    "            yp = mybest_model.predict(x)\n",
    "            cm = confusion_matrix(y, yp.ravel())\n",
    "            print(cm)\n",
    "            \n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    \n",
    "    plt.matshow(cm)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    if type_eval==1:\n",
    "\n",
    "        ntotal = len(set_test)\n",
    "        correct = set_test_cible[\"SELECTION\"].ravel() == set_test_cible_predicted\n",
    "        numCorrect = sum(correct)\n",
    "        percent = round((100.0 * numCorrect) / ntotal, 6)\n",
    "\n",
    "        print(\"Classification Correcte des données de test : {0:d}/{1:d}  {2:8.3f}%\".format(numCorrect, ntotal, percent))\n",
    "        prediction_score = 100.0 * mybest_model.score(set_test, set_test_cible)\n",
    "        print('\\nScore  TEST  : %8.3f  ************************' % prediction_score)\n",
    "\n",
    "    else:\n",
    "\n",
    "        ntotal = len(set_train)\n",
    "        correct = set_train_cible[\"SELECTION\"].ravel() == set_train_cible_predicted\n",
    "        numCorrect = sum(correct)\n",
    "        percent = round((100.0 * numCorrect) / ntotal, 6)\n",
    "\n",
    "        print(\"\\n CLASSIFICATION CORRECTE DES DONNEES DE Train : {0:d}/{1:d}  {2:8.3f}%\".format(numCorrect, ntotal, percent))\n",
    "        prediction_score = 100.0 * mybest_model.score(set_train, set_train_cible)\n",
    "        print('\\nScore  TRAINING  : %8.3f  ************************' % prediction_score)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain,dtrain_y, predictors,target,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain_y[target].values, silent=False)\n",
    "        \n",
    "        print(\"xgb.cv ....................\")\n",
    "        \n",
    "        cvresult = xgb.cv(xgb_param, \n",
    "                            xgtrain,\n",
    "                          num_boost_round=alg.get_params()['n_estimators'], \n",
    "                          nfold=cv_folds,\n",
    "                          verbose_eval=True,\n",
    "                          show_stdv=True,\n",
    "                         metrics='auc', \n",
    "                          early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    print(\"Fit the algorithm on the data..............\")\n",
    "    alg.fit(dtrain[predictors], dtrain_y['SELECTION'],eval_metric='auc')\n",
    "        \n",
    "    print(\"Predict training set:\")\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % accuracy_score(dtrain_y['SELECTION'].values, dtrain_predictions))\n",
    "           \n",
    "\n",
    "    \n",
    "        \n",
    "    return alg,cvresult,    dtrain_predictions,  dtrain_predprob\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entraine_allure_xgboost(allure, nb_iter, mode_debug=0, actualise=0):\n",
    "    # LECTURE DATA\n",
    "    global  df_gagnant, n_features, feature_columns, response_column , X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    print('---------------------ALLURE(  %s  )------------------------------------------------' % allure)\n",
    "    # Le fichier est lu meme si on  a le best model\n",
    "    df_gagnant, n_features, feature_columns, response_column = calul_data_allure(allure_etudier=allure, mode_debug=mode_debug)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    taille_training = 0.80\n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_gagnant[feature_columns], \n",
    "                                                        df_gagnant[response_column], \n",
    "                                                        test_size=1-taille_training,\n",
    "                                                        random_state=42)\n",
    "   \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------ALLURE(  1  )------------------------------------------------\n",
      "\n",
      "DF Après LECTURE --------------  d:\\diabollo_al_1.csv\n",
      "\n",
      " (638048, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(325096, 34)\n",
      "CO_DISTANCE                    int64\n",
      "CO_PRIX                        int64\n",
      "HIPPO                          int64\n",
      "PAR_CARRIERE                   int64\n",
      "PAR_CARRIERE_Q                 int64\n",
      "PAR_COTEDER                    int64\n",
      "PAR_ENT_ECART_GAGNANT          int64\n",
      "PAR_ENT_RAPPORT_GAGNANT_M    float64\n",
      "PAR_ENT_REU_PLACE            float64\n",
      "PAR_ENT_REUSSITE_GAGNE       float64\n",
      "PAR_ENT_VICTOIRE               int64\n",
      "pAR_JOC_ECART_GAGNANT          int64\n",
      "PAR_JOC_ECART_PLACE            int64\n",
      "PAR_JOC_NB_COURSE              int64\n",
      "PAR_JOC_PLACE_3P               int64\n",
      "pAR_JOC_RAPPORT_GAGNANT_M    float64\n",
      "PAR_JOC_REU_PLACE            float64\n",
      "pAR_JOC_REUSSITE_GAGNE       float64\n",
      "pAR_JOC_VICTOIRE               int64\n",
      "PAR_NUM                        int64\n",
      "PAR_PLACE                      int64\n",
      "PAR_PLACE_Q                    int64\n",
      "PAR_REUSSITE_3P              float64\n",
      "PAR_REUSSITE_GAGNE           float64\n",
      "PAR_REUSSITE_QUINTE          float64\n",
      "PAR_RUESSITE_PLACE           float64\n",
      "autostart                      int64\n",
      "Point                          int64\n",
      "Nb_partant                     int64\n",
      "PAR_PROPRIO                    int64\n",
      "NOM_JOC                        int64\n",
      "NOM_ENTR                       int64\n",
      "CHEVAL                         int64\n",
      "SELECTION                      int64\n",
      "dtype: object\n",
      "Features                   :   ['CO_DISTANCE', 'CO_PRIX', 'HIPPO', 'PAR_CARRIERE', 'PAR_CARRIERE_Q', 'PAR_COTEDER', 'PAR_ENT_ECART_GAGNANT', 'PAR_ENT_RAPPORT_GAGNANT_M', 'PAR_ENT_REU_PLACE', 'PAR_ENT_REUSSITE_GAGNE', 'PAR_ENT_VICTOIRE', 'pAR_JOC_ECART_GAGNANT', 'PAR_JOC_ECART_PLACE', 'PAR_JOC_NB_COURSE', 'PAR_JOC_PLACE_3P', 'pAR_JOC_RAPPORT_GAGNANT_M', 'PAR_JOC_REU_PLACE', 'pAR_JOC_REUSSITE_GAGNE', 'pAR_JOC_VICTOIRE', 'PAR_NUM', 'PAR_PLACE', 'PAR_PLACE_Q', 'PAR_REUSSITE_3P', 'PAR_REUSSITE_GAGNE', 'PAR_REUSSITE_QUINTE', 'PAR_RUESSITE_PLACE', 'autostart', 'Point', 'Nb_partant', 'PAR_PROPRIO', 'NOM_JOC', 'NOM_ENTR', 'CHEVAL']  <<<<************\n",
      "Nombre de feature   :   33\n",
      "Colonne cible            :  ['SELECTION']\n",
      "FEATURES COLONNES            :  ['CO_DISTANCE', 'CO_PRIX', 'HIPPO', 'PAR_CARRIERE', 'PAR_CARRIERE_Q', 'PAR_COTEDER', 'PAR_ENT_ECART_GAGNANT', 'PAR_ENT_RAPPORT_GAGNANT_M', 'PAR_ENT_REU_PLACE', 'PAR_ENT_REUSSITE_GAGNE', 'PAR_ENT_VICTOIRE', 'pAR_JOC_ECART_GAGNANT', 'PAR_JOC_ECART_PLACE', 'PAR_JOC_NB_COURSE', 'PAR_JOC_PLACE_3P', 'pAR_JOC_RAPPORT_GAGNANT_M', 'PAR_JOC_REU_PLACE', 'pAR_JOC_REUSSITE_GAGNE', 'pAR_JOC_VICTOIRE', 'PAR_NUM', 'PAR_PLACE', 'PAR_PLACE_Q', 'PAR_REUSSITE_3P', 'PAR_REUSSITE_GAGNE', 'PAR_REUSSITE_QUINTE', 'PAR_RUESSITE_PLACE', 'autostart', 'Point', 'Nb_partant', 'PAR_PROPRIO', 'NOM_JOC', 'NOM_ENTR', 'CHEVAL']\n",
      "\n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "entraine_allure_xgboost(allure=1,   nb_iter=1,   mode_debug=0,   actualise=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECHERCHE DES BONS PARAMETRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1b8ca579f05f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m                                         scoring='roc_auc', verbose=True,iid=False, cv=10  ,refit=True)          \n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mgsearch1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SELECTION'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[0;32m    504\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m--> 898\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m    899\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "params={\n",
    "    'learning_rate': [1 / i for i in range(10, 100)],\n",
    "    'n_estimators':[75,100,125],\n",
    "    'max_depth':[5,6,8,9],\n",
    "    'min_child_weight': [3,5, 7, 9,11]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "gsearch1 = RandomizedSearchCV(estimator = xgb.XGBClassifier( subsample=0.9,\n",
    "                                                             colsample_bytree=0.8,\n",
    "                                                             silent=False   ,\n",
    "                                                       gamma=0,    objective= 'binary:logistic', \n",
    "                                                   scale_pos_weight=1,   seed=1000)  , \n",
    "                                                   n_iter =50,\n",
    "                                                 param_distributions=params, \n",
    "                                        scoring='roc_auc', verbose=True,iid=False, cv=10  ,refit=True)          \n",
    "\n",
    "gsearch1.fit(X_train,y_train['SELECTION'].ravel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\",gsearch1.grid_scores_) \n",
    "print(\"\\n\",gsearch1.best_params_)\n",
    "print(\"\\n\",gsearch1.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gsearch1.best_estimator_\n",
    "eval_set=[(X_test, y_test)]\n",
    "model.fit(X_train, y_train[\"SELECTION\"].ravel(), eval_metric=\"error\", eval_set=eval_set, verbose=False)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test[\"SELECTION\"].ravel(), predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "model.fit(X_train, y_train, eval_metric=[\"error\", \"logloss\"], eval_set=eval_set, verbose=False)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "# retrieve performance metrics\n",
    "results = model.evals_result()\n",
    "epochs = len(results['validation_0']['error'])\n",
    "x_axis = range(0, epochs)\n",
    "# plot log loss\n",
    "fig, ax = pyplot.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "ax.legend()\n",
    "pyplot.ylabel('Log Loss')\n",
    "pyplot.title('XGBoost Log Loss')\n",
    "pyplot.show()\n",
    "# plot classification error\n",
    "fig, ax = pyplot.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "ax.legend()\n",
    "pyplot.ylabel('Classification Error')\n",
    "pyplot.title('XGBoost Classification Error')\n",
    "pyplot.show()    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_predictor_importance(model,feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
