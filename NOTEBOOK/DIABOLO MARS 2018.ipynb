{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import scipy\n",
    "import platform\n",
    "import sys\n",
    "import sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, classification_report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, average_precision_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import  metrics\n",
    "from time import time\n",
    "import scipy.stats as st\n",
    "from operator import itemgetter\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating system version.... Windows-10-10.0.16299-SP0\n",
      "Python version is........... 3.6.3\n",
      "scikit-learn version is..... 0.19.1\n",
      "pandas version is........... 0.22.0\n",
      "numpy version is............ 1.12.1\n",
      "matplotlib version is....... 2.1.2\n",
      "scipy version is....... 1.0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Operating system version....', platform.platform())\n",
    "print(\"Python version is........... %s.%s.%s\" % sys.version_info[:3])\n",
    "print('scikit-learn version is.....', sklearn.__version__)\n",
    "print('pandas version is...........', pd.__version__)\n",
    "print('numpy version is............', np.__version__)\n",
    "print('matplotlib version is.......', matplotlib.__version__)\n",
    "print('scipy version is.......', scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "  def __init__(self):\n",
    "    self.start = time.time()\n",
    "\n",
    "  def restart(self):\n",
    "    self.start = time.time()\n",
    "\n",
    "  def get_time(self):\n",
    "    end = time.time()\n",
    "    m, s = divmod(end - self.start, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    time_str = \"%02d:%02d:%02d\" % (h, m, s)\n",
    "    return time_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_dataset(dataset, train_percentage, feature_headers,\n",
    "                                  target_header,random_state=42,mode_debug=0):\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(dataset[feature_headers], dataset[target_header],\n",
    "                                                        train_size=train_percentage, test_size=None, random_state=42)\n",
    "\n",
    "\n",
    "    if mode_debug==1:\n",
    "        # Train and Test dataset size details\n",
    "        print(\"--------------------------------\")\n",
    "        print(\"Train_x Shape :: \", train_x.shape)\n",
    "        print(\"Train_y Shape :: \", train_y.shape)\n",
    "        print(\"Test_x Shape :: \", test_x.shape)\n",
    "        print(\"Test_y Shape :: \", test_y.shape)\n",
    "        print(\"--------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lecture_data(Fichier, xnames, xindex_col, allure=1, mode_debug=0,avec_index=True):\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    if  avec_index==True:\n",
    "        df = pd.read_csv(Fichier,\n",
    "                     index_col=xindex_col,\n",
    "                     sep=';',\n",
    "                     names=xnames, skipinitialspace=True,\n",
    "                     encoding='Latin-1')\n",
    "    else:\n",
    "        df = pd.read_csv(Fichier,\n",
    "                         index_col=None,\n",
    "                         sep=';',\n",
    "                         names=xnames, skipinitialspace=True,\n",
    "                         encoding='Latin-1')\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nDF Après LECTURE -------------- \",Fichier)\n",
    "\n",
    "    print(\"\\n\",df.shape)\n",
    "#    print(\"\\n\",df.head(5))\n",
    "\n",
    "\n",
    "    if  avec_index==False:\n",
    "        df.drop([\"IDPARTCIPANT\"], axis=1, inplace=True)\n",
    "        df.drop([\"IDCOURSE\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    df.drop([\"FIN_ligne\"], axis=1, inplace=True)\n",
    "    df.drop([\"PAR_NP\"], axis=1, inplace=True)\n",
    "    df.drop([\"cendre\"], axis=1, inplace=True)\n",
    "    df.drop([\"CO_PRIX\"], axis=1, inplace=True)\n",
    "    df.drop([\"PAR_CLASSE_AGE\"], axis=1, inplace=True)\n",
    "    #df.drop([\"PAR_AGE\"], axis=1, inplace=True)\n",
    "    df.drop([\"grande_piste\"], axis=1, inplace=True)\n",
    "    df.drop([\"PAR_COTEDER\"], axis=1, inplace=True)\n",
    "    #df=my_drop(df, \"HIPPO\")\n",
    "    df=my_drop(df, \"PAR_AGE\")\n",
    "    df = my_drop(df, \"PAR_GAIN\")\n",
    "\n",
    "\n",
    "\n",
    "    if allure==1:\n",
    "        df.drop([\"POIDS\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    if allure == 2:\n",
    "        df.drop([\"autostart\"], axis=1, inplace=True)\n",
    "        df.drop([\"CO_DISTANCE\"], axis=1, inplace=True)\n",
    "\n",
    "    if allure == 3:\n",
    "        df.drop([\"POIDS\"], axis=1, inplace=True)\n",
    "\n",
    "    if allure == 4:\n",
    "        df.drop([\"autostart\"], axis=1, inplace=True)\n",
    "        df.drop([\"CO_DISTANCE\"], axis=1, inplace=True)\n",
    "\n",
    "    if allure == 5:\n",
    "        df.drop([\"autostart\"], axis=1, inplace=True)\n",
    "        df.drop([\"CO_DISTANCE\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def my_split(taille_entrainement, df,feature_columns,response_column ,random_state=42,mode_debug=0):\n",
    "    train_x, test_x, train_y, test_y = split_dataset(df,\n",
    "                                                         taille_entrainement,\n",
    "                                                          feature_columns,\n",
    "                                                          response_column,\n",
    "                                                         random_state=random_state,\n",
    "                                                     mode_debug=mode_debug\n",
    "                                                     )\n",
    "\n",
    "    return train_x, test_x, train_y, test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_drop(df, col):\n",
    "\n",
    "    if col in df:\n",
    "        df.drop([col], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Creating bins for the win column\n",
    "def assign_selection(W):\n",
    "    if W <5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def save_mymodel(clf,allure):\n",
    "    joblib.dump(clf,'diabolo'+str(allure)+'.pkl')\n",
    "\n",
    "\n",
    "def load_mymodel(allure):\n",
    "    clf=joblib.load('diabolo'+str(allure)+'.pkl')\n",
    "    return clf\n",
    "\n",
    "\n",
    "#Définir une méthode pour tracer l'importance du prédicteur\n",
    "def Plot_predictor_importance(best_model, feature_columns):\n",
    "    feature_importance = best_model.feature_importances_\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    y_pos  = np.arange(sorted_idx.shape[0]) + .7\n",
    "    fig, ax = plt.subplots( figsize=(10, 10))\n",
    "\n",
    "\n",
    "\n",
    "    ax.barh(y_pos,\n",
    "            feature_importance[sorted_idx],\n",
    "            align='center',\n",
    "            color='green',\n",
    "            ecolor='black',\n",
    "            height=0.8)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(feature_columns)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "\n",
    "\n",
    "    ax.set_xlabel('Relative Importance')\n",
    "    ax.set_title('Predictor Importance')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def calul_data_allure(allure_etudier, mode_debug=0,avec_index=True):\n",
    "\n",
    "    xnames = ['ALLURE'  , 'CO_DISTANCE',\n",
    "              'CO_PRIX',  'HIPPO',\n",
    "              'IDCOURSE', 'IDPARTCIPANT',\n",
    "              'PAR_AGE',      'PAR_ARRIVE',\n",
    "              'PAR_CARRIERE',\n",
    "              'PAR_CARRIERE_Q',\n",
    "              'PAR_CLASSE_AGE',\n",
    "              'PAR_COTEDER',\n",
    "              'PAR_ENT_ECART_GAGNANT',\n",
    "              'PAR_ENT_RAPPORT_GAGNANT_M',\n",
    "              'PAR_ENT_REU_PLACE',\n",
    "              'PAR_ENT_REUSSITE_GAGNE',\n",
    "              'PAR_ENT_VICTOIRE',\n",
    "              'PAR_GAIN',\n",
    "              'pAR_JOC_ECART_GAGNANT',\n",
    "              'PAR_JOC_ECART_PLACE',\n",
    "              'PAR_JOC_NB_COURSE',\n",
    "              'PAR_JOC_PLACE_3P',\n",
    "              'pAR_JOC_RAPPORT_GAGNANT_M',\n",
    "              'PAR_JOC_REU_PLACE',\n",
    "              'pAR_JOC_REUSSITE_GAGNE',\n",
    "              'pAR_JOC_VICTOIRE',\n",
    "              'PAR_NP',\n",
    "              'PAR_NUM',\n",
    "              'PAR_PLACE',\n",
    "              'PAR_PLACE_Q',\n",
    "              'PAR_REUSSITE_3P',\n",
    "              'PAR_REUSSITE_GAGNE',\n",
    "              'PAR_REUSSITE_QUINTE',\n",
    "              'PAR_RUESSITE_PLACE',\n",
    "              'autostart',\n",
    "              'cendre',\n",
    "              'grande_piste',\n",
    "              'Point',\n",
    "              'Nb_partant','PAR_PROPRIO',\n",
    "                                         'NOM_JOC',\n",
    "                                         'NOM_ENTR',\n",
    "                                        'POIDS',\n",
    "                                         'FIN_ligne']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df = lecture_data('d:\\diabollo_al_1.csv', xnames, ['IDPARTCIPANT', 'IDCOURSE'],allure=allure_etudier,avec_index=avec_index)\n",
    "\n",
    "\n",
    "    # groupage par allure\n",
    "    df = df.groupby(\"ALLURE\")\n",
    "    df = df.get_group(allure_etudier)\n",
    "    #df.head(5)\n",
    "    df = my_drop(df, 'ALLURE')\n",
    "    # Contruction de df_gagant\n",
    "    df_gagnant = df\n",
    "    # les lignes sans arrivée n'apportent rien !!!!\n",
    "    df_gagnant = df_gagnant[df_gagnant.PAR_ARRIVE > 0]  # On garde la ligne qui possede information arrivée\n",
    "    #df_gagnant = df_gagnant[df_gagnant.PAR_GAIN < 20000000]\n",
    "    #df_gagnant = df_gagnant[df_gagnant.PAR_GAIN > 0]\n",
    "\n",
    "\n",
    "\n",
    "    if allure_etudier==2:\n",
    "        df_gagnant = df_gagnant[df_gagnant.POIDS > 0]\n",
    "        df_gagnant = df_gagnant[df_gagnant.POIDS < 100]\n",
    "\n",
    "\n",
    "\n",
    "    # Shape des données df_gagant\n",
    "    if  mode_debug==1:\n",
    "        print(\" df_gagnant \", df_gagnant.shape)\n",
    "        COLUM = df_gagnant.columns\n",
    "        print(\"Features\", COLUM )\n",
    "\n",
    "    # Construction de la cible\n",
    "    df_gagnant['SELECTION'] = df_gagnant['PAR_ARRIVE'].apply(assign_selection)\n",
    "\n",
    "    #df_gagnant = df_gagnant[df_gagnant.PAR_COTEDER < 150]\n",
    "     # Suppression de la colonne qui a permis de construire la cible : PAR_ARRIVE\n",
    "    df_gagnant.drop([\"PAR_ARRIVE\"], axis=1, inplace=True)\n",
    "\n",
    "    print(\"\\ndf_gagnant \\n\", df_gagnant.shape)  # description de l'ensemble\n",
    "        # pd.DataFrame.hist(df_gagnant, figsize = [15,15]);\n",
    "\n",
    "\n",
    "    df_gagnant_len            = len(df_gagnant.columns) - 1\n",
    "    Lib_features                = list(df_gagnant.columns[:df_gagnant_len])  # Liebllé des variable DATA\n",
    "    feature_columns         = Lib_features ##<<<<<<<<<<<<<<<<\n",
    "    n_features = len(feature_columns) ##<<<<<<<<<<<<<<<<\n",
    "    response_column = ['SELECTION']  ##<<<<<<<<<<<<<<<<\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Features                   :  \", Lib_features, \" <<<<************\")\n",
    "\n",
    "    print(\"Nombre de feature   :  \", n_features)\n",
    "    print(\"Colonne cible            : \", response_column)\n",
    "    print(\"FEATURES COLONNES            : \", feature_columns)\n",
    "    print(\"\\n\\n------------------------------------------------\")\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    return df_gagnant, n_features, feature_columns, response_column    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************************************************************************************\n",
    "def entraine_allure(allure, nb_iter,mode_debug=0, actualise=0):\n",
    "    # LECTURE DATA\n",
    "    print('---------------------ALLURE(  %s  )------------------------------------------------' % allure)\n",
    "    # Le fichier est lu meme si on  a le best model\n",
    "    df_gagnant, n_features, feature_columns, response_column = lecture_data.calul_data_allure(allure_etudier = allure,mode_debug=mode_debug)\n",
    "\n",
    "\n",
    "    if actualise==0:\n",
    "\n",
    "        #estimateur = GradientBoostingClassifier\n",
    "        estimateur = XGBClassifier\n",
    "        taille_training = 0.85\n",
    "        train_x, test_x, train_y, test_y = my_split(df=df_gagnant,\n",
    "                                                                              taille_entrainement=taille_training,\n",
    "                                                                              feature_columns =feature_columns,\n",
    "                                                                              response_column =response_column,\n",
    "                                                                               random_state=42,\n",
    "                                                                               mode_debug=mode_debug)\n",
    "        #best_model= analyse.fit_xg(X_train=train_x, y_train=train_y, X_test =test_x,y_test=test_y)\n",
    "        best_model = my_fit(estimateur=estimateur,\n",
    "                                        nb_iter=nb_iter, my_nb_splits=10,\n",
    "                                       my_test_size=1 - taille_training,\n",
    "                                        my_random_state=0,\n",
    "                                        train_x=train_x, train_y=train_y,allure=allure,featurecolums=feature_columns)\n",
    "\n",
    "\n",
    "\n",
    "        Plot_predictor_importance(best_model, feature_columns)\n",
    "\n",
    "\n",
    "\n",
    "        # sauvegarde du modele\n",
    "        save_mymodel(clf=best_model,allure=allure)\n",
    "\n",
    "        # EVALUATION\n",
    "        evaluation(mybest_model=best_model, train_x=train_x, test_x=test_x,\n",
    "                           train_y=train_y, test_y=test_y, mode_debug=mode_debug)\n",
    "\n",
    "    else:\n",
    "        # CHARGEMENT DU MODELE\n",
    "        best_model = lecture_data.load_mymodel(allure)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return best_model, feature_columns, response_column\n",
    "\n",
    "\n",
    "\n",
    "#Définir une fonction d'utilité pour signaler les meilleurs scores\n",
    "def Report_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def afficheEvalSet(mybest_model,\n",
    "                    set_train,\n",
    "                   set_train_cible,\n",
    "                   set_test,\n",
    "                   set_test_cible,\n",
    "                   mode_debug=0,\n",
    "                   type_eval=1):\n",
    "\n",
    "\n",
    "    set_test_cible_predicted = mybest_model.predict(set_test)\n",
    "    set_train_cible_predicted = mybest_model.predict(set_train)\n",
    "\n",
    "    if type_eval==1:\n",
    "                print(\"Evaluation TEST-----------------------------------------------------------------------\")\n",
    "\n",
    "                set_test_cible_probabilities = mybest_model.predict_proba(set_test)\n",
    "                auc = roc_auc_score(set_test_cible, set_test_cible_predicted)\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "                print(\"Evaluation TRAINING--------------------------------------------------------------------\")\n",
    "\n",
    "                set_train_cible_probabilities = mybest_model.predict_proba(set_train)\n",
    "                auc = roc_auc_score(set_train_cible, set_train_cible_predicted)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n roc_auc_score :  \", auc)\n",
    "    if mode_debug == 1:\n",
    "        for x, y in [(set_train, set_train_cible), (set_test, set_test_cible)]:\n",
    "            yp = mybest_model.predict(x)\n",
    "            cm = confusion_matrix(y, yp.ravel())\n",
    "            print(cm)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if mode_debug == 1:\n",
    "        plt.matshow(cm)\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.colorbar()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "    if type_eval==1:\n",
    "\n",
    "        ntotal = len(set_test)\n",
    "        correct = set_test_cible[\"SELECTION\"].ravel() == set_test_cible_predicted\n",
    "        numCorrect = sum(correct)\n",
    "        percent = round((100.0 * numCorrect) / ntotal, 6)\n",
    "\n",
    "        print(\"Classification Correcte des données de test : {0:d}/{1:d}  {2:8.3f}%\".format(numCorrect, ntotal, percent))\n",
    "        prediction_score = 100.0 * mybest_model.score(set_test, set_test_cible)\n",
    "        print('\\nScore  TEST  : %8.3f  ************************' % prediction_score)\n",
    "\n",
    "    else:\n",
    "\n",
    "        ntotal = len(set_train)\n",
    "        correct = set_train_cible[\"SELECTION\"].ravel() == set_train_cible_predicted\n",
    "        numCorrect = sum(correct)\n",
    "        percent = round((100.0 * numCorrect) / ntotal, 6)\n",
    "\n",
    "        print(\"\\n CLASSIFICATION CORRECTE DES DONNEES DE Train : {0:d}/{1:d}  {2:8.3f}%\".format(numCorrect, ntotal, percent))\n",
    "        prediction_score = 100.0 * mybest_model.score(set_train, set_train_cible)\n",
    "        print('\\nScore  TRAINING  : %8.3f  ************************' % prediction_score)\n",
    "\n",
    "        \n",
    "def evaluation(mybest_model,\n",
    "                  train_x, test_x,\n",
    "                   train_y, test_y,\n",
    "                    mode_debug=0):\n",
    "\n",
    "\n",
    "    afficheEvalSet(mybest_model=mybest_model,\n",
    "                         set_train=train_x,\n",
    "                         set_train_cible=train_y,\n",
    "                         set_test=test_x,\n",
    "                          set_test_cible=test_y,\n",
    "                   mode_debug=mode_debug, type_eval=1)\n",
    "\n",
    "    afficheEvalSet(mybest_model=mybest_model,\n",
    "                         set_train=train_x,\n",
    "                         set_train_cible=train_y,\n",
    "                         set_test=test_x,\n",
    "                          set_test_cible=test_y,\n",
    "                   mode_debug=mode_debug, type_eval=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def  my_randomize_estimateur(estimateur, train_x, train_y,nb_iteration, verbose,allure,my_scoring=\"roc_auc\"):\n",
    "\n",
    "\n",
    "\n",
    "        #param_grid = dict(learning_rate=learning_rate,                          n_estimators=n_estimators)\n",
    "\n",
    "        if allure==1:\n",
    "            param_grid = {\n",
    "             'silent': [False],\n",
    "             'max_depth': [6 ],\n",
    "              #'min_samples_split': [3000,3200],\n",
    "             'learning_rate': [0.05],\n",
    "             'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "             'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "             'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "             'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "             'gamma': [0.25],\n",
    "            'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "            'n_estimators': [100]\n",
    "           }\n",
    "\n",
    "\n",
    "        if allure==2:\n",
    "              param_grid = {        'silent': [False],\n",
    "                   'max_depth': [7,14] ,\n",
    "                    'learning_rate': [0.05],\n",
    "                   'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                   'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                   'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                   'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "                   'gamma': [0.25],\n",
    "                   'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "                  'n_estimators': [150,175,200]\n",
    "              }\n",
    "\n",
    "        if allure == 3:\n",
    "            param_grid = {'silent': [False],\n",
    "                          'max_depth': [7],\n",
    "                          #  'min_samples_split': [2500, 3000, 4000],\n",
    "                          'learning_rate': [0.05],\n",
    "                          'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                          'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                          'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                          'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "                          'gamma': [0.25],\n",
    "                          'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "                          'n_estimators': [150]\n",
    "                          }\n",
    "        if allure == 4:\n",
    "            param_grid = {'silent': [False],\n",
    "                          'max_depth': [7],\n",
    "                          #  'min_samples_split': [2500, 3000, 4000],\n",
    "                          'learning_rate': [0.05],\n",
    "                          'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                          'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                          'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                          'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "                          'gamma': [0.25],\n",
    "                          'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "                          'n_estimators': [150]\n",
    "                          }\n",
    "        if allure == 5:\n",
    "                param_grid = {'silent': [False],\n",
    "                              'max_depth': [7],\n",
    "                              #  'min_samples_split': [2500, 3000, 4000],\n",
    "                              'learning_rate': [0.05],\n",
    "                              'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                              'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                              'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                              'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "                              'gamma': [0.25],\n",
    "                              'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "                              'n_estimators': [150]\n",
    "                              }\n",
    "\n",
    "        clf=XGBClassifier()\n",
    "        estimator = RandomizedSearchCV(clf,\n",
    "                                    param_distributions=param_grid, scoring=my_scoring,\n",
    "                                     verbose=3, n_iter=nb_iteration,n_jobs=-1,cv=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def my_fit(estimateur,          nb_iter, my_nb_splits, my_test_size,\n",
    "                                    my_random_state, train_x, train_y, featurecolums, allure, mode_debug=0):\n",
    "\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "    my_timer = Timer()\n",
    "\n",
    "    estimator = my_randomize_estimateur(estimateur, train_x=train_x,train_y=train_y, allure=allure,nb_iteration=nb_iter, verbose=2, my_scoring=\"roc_auc\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    estimator.fit(train_x, train_y[\"SELECTION\"].ravel(), verbose=True)\n",
    "\n",
    "\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = estimator.cv_results_['mean_test_score']\n",
    "    print(means)\n",
    "\n",
    "    stds = estimator.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, estimator.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    elapsed = my_timer.get_time()\n",
    "    print(\"\\n\\nTemps de calcul du FIT  est : %s\" % elapsed)\n",
    "\n",
    "    print(\"Report score \\n\")\n",
    "    Report_scores(estimator.cv_results_, n_top=nb_iter)\n",
    "    # Plot_learning_curve(estimator, '', train_x, train_y[\"SELECTION\"].ravel(),cv=cv_, n_jobs=4)\n",
    "    best_model = estimator.best_estimator_  # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "    print('\\nbest_model                                  : ', best_model)\n",
    "    # print('\\nbest_model Nombre de Feature  :  ', best_model.n_features_)\n",
    "    print('\\nbest_model  Classes                      : ', best_model.classes_)\n",
    "   # print('\\nbest_model  best_params_           : ', best_model.best_params_)\n",
    "\n",
    "    best_score = estimator.best_score_  # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "    print(\"\\nBEST SCORE = \", best_score)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calul_data_allure(allure_etudier, mode_debug=0,avec_index=True):\n",
    "\n",
    "    xnames = ['ALLURE'  , 'CO_DISTANCE',\n",
    "              'CO_PRIX',  'HIPPO',\n",
    "              'IDCOURSE', 'IDPARTCIPANT',\n",
    "              'PAR_AGE',      'PAR_ARRIVE',\n",
    "              'PAR_CARRIERE',\n",
    "              'PAR_CARRIERE_Q',\n",
    "              'PAR_CLASSE_AGE',\n",
    "              'PAR_COTEDER',\n",
    "              'PAR_ENT_ECART_GAGNANT',\n",
    "              'PAR_ENT_RAPPORT_GAGNANT_M',\n",
    "              'PAR_ENT_REU_PLACE',\n",
    "              'PAR_ENT_REUSSITE_GAGNE',\n",
    "              'PAR_ENT_VICTOIRE',\n",
    "              'PAR_GAIN',\n",
    "              'pAR_JOC_ECART_GAGNANT',\n",
    "              'PAR_JOC_ECART_PLACE',\n",
    "              'PAR_JOC_NB_COURSE',\n",
    "              'PAR_JOC_PLACE_3P',\n",
    "              'pAR_JOC_RAPPORT_GAGNANT_M',\n",
    "              'PAR_JOC_REU_PLACE',\n",
    "              'pAR_JOC_REUSSITE_GAGNE',\n",
    "              'pAR_JOC_VICTOIRE',\n",
    "              'PAR_NP',\n",
    "              'PAR_NUM',\n",
    "              'PAR_PLACE',\n",
    "              'PAR_PLACE_Q',\n",
    "              'PAR_REUSSITE_3P',\n",
    "              'PAR_REUSSITE_GAGNE',\n",
    "              'PAR_REUSSITE_QUINTE',\n",
    "              'PAR_RUESSITE_PLACE',\n",
    "              'autostart',\n",
    "              'cendre',\n",
    "              'grande_piste',\n",
    "              'Point',\n",
    "              'Nb_partant','PAR_PROPRIO',\n",
    "                                         'NOM_JOC',\n",
    "                                         'NOM_ENTR',\n",
    "                                        'POIDS',\n",
    "                                         'FIN_ligne']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df = lecture_data('d:\\diabollo_al_1.csv', xnames, ['IDPARTCIPANT', 'IDCOURSE'],allure=allure_etudier,avec_index=avec_index)\n",
    "\n",
    "\n",
    "    # groupage par allure\n",
    "    df = df.groupby(\"ALLURE\")\n",
    "    df = df.get_group(allure_etudier)\n",
    "    #df.head(5)\n",
    "    df = my_drop(df, 'ALLURE')\n",
    "    # Contruction de df_gagant\n",
    "    df_gagnant = df\n",
    "    # les lignes sans arrivée n'apportent rien !!!!\n",
    "    df_gagnant = df_gagnant[df_gagnant.PAR_ARRIVE > 0]  # On garde la ligne qui possede information arrivée\n",
    "    #df_gagnant = df_gagnant[df_gagnant.PAR_GAIN < 20000000]\n",
    "    #df_gagnant = df_gagnant[df_gagnant.PAR_GAIN > 0]\n",
    "\n",
    "\n",
    "\n",
    "    if allure_etudier==2:\n",
    "        df_gagnant = df_gagnant[df_gagnant.POIDS > 0]\n",
    "        df_gagnant = df_gagnant[df_gagnant.POIDS < 100]\n",
    "\n",
    "\n",
    "\n",
    "    # Shape des données df_gagant\n",
    "    if  mode_debug==1:\n",
    "        print(\" df_gagnant \", df_gagnant.shape)\n",
    "        COLUM = df_gagnant.columns\n",
    "        print(\"Features\", COLUM )\n",
    "\n",
    "    # Construction de la cible\n",
    "    df_gagnant['SELECTION'] = df_gagnant['PAR_ARRIVE'].apply(assign_selection)\n",
    "\n",
    "    #df_gagnant = df_gagnant[df_gagnant.PAR_COTEDER < 150]\n",
    "     # Suppression de la colonne qui a permis de construire la cible : PAR_ARRIVE\n",
    "    df_gagnant.drop([\"PAR_ARRIVE\"], axis=1, inplace=True)\n",
    "\n",
    "    print(\"\\ndf_gagnant \\n\", df_gagnant.shape)  # description de l'ensemble\n",
    "        # pd.DataFrame.hist(df_gagnant, figsize = [15,15]);\n",
    "\n",
    "\n",
    "    df_gagnant_len            = len(df_gagnant.columns) - 1\n",
    "    Lib_features                = list(df_gagnant.columns[:df_gagnant_len])  # Liebllé des variable DATA\n",
    "    feature_columns         = Lib_features ##<<<<<<<<<<<<<<<<\n",
    "    n_features = len(feature_columns) ##<<<<<<<<<<<<<<<<\n",
    "    response_column = ['SELECTION']  ##<<<<<<<<<<<<<<<<\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Features                   :  \", Lib_features, \" <<<<************\")\n",
    "\n",
    "    print(\"Nombre de feature   :  \", n_features)\n",
    "    print(\"Colonne cible            : \", response_column)\n",
    "    print(\"FEATURES COLONNES            : \", feature_columns)\n",
    "    print(\"\\n\\n------------------------------------------------\")\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    return df_gagnant, n_features, feature_columns, response_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construireFichierCSV(allure, best_model, feature_columns, response_column, mode_debug=0):\n",
    "    # lecture des données a jouer\n",
    "\n",
    "\n",
    "    xnames = ['ALLURE', 'CO_DISTANCE',\n",
    "              'CO_PRIX', 'HIPPO',\n",
    "              'IDCOURSE', 'IDPARTCIPANT',\n",
    "              'PAR_AGE', 'PAR_ARRIVE',\n",
    "              'PAR_CARRIERE',\n",
    "              'PAR_CARRIERE_Q',\n",
    "              'PAR_CLASSE_AGE',\n",
    "              'PAR_COTEDER',\n",
    "              'PAR_ENT_ECART_GAGNANT',\n",
    "              'PAR_ENT_RAPPORT_GAGNANT_M',\n",
    "              'PAR_ENT_REU_PLACE',\n",
    "              'PAR_ENT_REUSSITE_GAGNE',\n",
    "              'PAR_ENT_VICTOIRE',\n",
    "              'PAR_GAIN',\n",
    "              'pAR_JOC_ECART_GAGNANT',\n",
    "              'PAR_JOC_ECART_PLACE',\n",
    "              'PAR_JOC_NB_COURSE',\n",
    "              'PAR_JOC_PLACE_3P',\n",
    "              'pAR_JOC_RAPPORT_GAGNANT_M',\n",
    "              'PAR_JOC_REU_PLACE',\n",
    "              'pAR_JOC_REUSSITE_GAGNE',\n",
    "              'pAR_JOC_VICTOIRE',\n",
    "              'PAR_NP',\n",
    "              'PAR_NUM',\n",
    "              'PAR_PLACE',\n",
    "              'PAR_PLACE_Q',\n",
    "              'PAR_REUSSITE_3P',\n",
    "              'PAR_REUSSITE_GAGNE',\n",
    "              'PAR_REUSSITE_QUINTE',\n",
    "              'PAR_RUESSITE_PLACE',\n",
    "              'autostart',\n",
    "              'cendre',\n",
    "              'grande_piste',\n",
    "              'Point',\n",
    "              'Nb_partant', 'PAR_PROPRIO',\n",
    "              'NOM_JOC',\n",
    "              'NOM_ENTR',\n",
    "              'POIDS',\n",
    "              'FIN_ligne']\n",
    "\n",
    "\n",
    "\n",
    "    df_numero_a_predire = lecture_data.lecture_data('d:\\diabollo_al_1_D.csv', xnames, ['IDPARTCIPANT', 'IDCOURSE'],allure=allure)\n",
    "\n",
    "\n",
    "\n",
    "    if allure==5:\n",
    "        print(\"\\nSHAPE Numero a predire\")\n",
    "        print(df_numero_a_predire.shape)\n",
    "\n",
    "\n",
    "\n",
    "    df_numero_a_predire = df_numero_a_predire.groupby(\"ALLURE\")\n",
    "    df_numero_a_predire = df_numero_a_predire.get_group(allure)\n",
    "    df_numero_a_predire = lecture_data.my_drop(df_numero_a_predire, 'ALLURE')\n",
    "\n",
    "    df_numero_a_predire = lecture_data.my_drop(df_numero_a_predire, 'PAR_ARRIVE')\n",
    "\n",
    "    if mode_debug == 1:\n",
    "        print(\"\\nSHAPE Numero a predire\")\n",
    "        print(df_numero_a_predire.shape)\n",
    "\n",
    "    my_timer = analyse.Timer()\n",
    "\n",
    "\n",
    "    df_numero_a_predire['SELECTION'] = 0\n",
    "\n",
    "    train_x, test_x, train_y, test_y = analyse.split_dataset(df_numero_a_predire, 0, feature_columns, response_column)\n",
    "   # print(test_x.head(2))\n",
    "    print(test_x.shape)\n",
    "\n",
    "\n",
    "    # sauvegarde\n",
    "    y_pred = best_model.predict(test_x)\n",
    "    if mode_debug == 1:\n",
    "        print(\"y pred\")\n",
    "        print(y_pred)\n",
    "\n",
    "    df_pred = pd.DataFrame.from_dict(y_pred)\n",
    "    test_copy = test_x.copy()\n",
    "\n",
    "\n",
    "    # print(df_pred)\n",
    "    #print(\"PREDICTION COURSES A JOUER\")\n",
    "    if mode_debug==1:\n",
    "        print(y_pred)\n",
    "\n",
    "\n",
    "    # UTILISATION DE BEST_MODEL\n",
    "    PROBA = best_model.predict_proba(test_x)\n",
    "    #print(\"PROBA \\n %s\" ,PROBA)\n",
    "\n",
    "    df_proba = pd.DataFrame.from_dict(PROBA)\n",
    "\n",
    "    #print(\"df final=\")\n",
    "    df_final = pd.concat([df_proba, df_pred], axis=1)\n",
    "\n",
    "    if mode_debug==1:\n",
    "        print(\"SHAPE df_final\")\n",
    "        print(df_final.shape)\n",
    "\n",
    "\n",
    "    test_x = test_copy.copy()\n",
    "\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_CLASSE_AGE')\n",
    "\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_ENT_ECART_GAGNANT')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_ENT_RAPPORT_GAGNANT_M')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_ENT_REU_PLACE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_ENT_REUSSITE_GAGNE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_ENT_VICTOIRE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_GAIN')\n",
    "    test_x = lecture_data.my_drop(test_x, 'pAR_JOC_ECART_GAGNANT')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_JOC_ECART_PLACE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_JOC_NB_COURSE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_JOC_PLACE_3P')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_REUSSITE_GAGNE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_REUSSITE_QUINTE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_RUESSITE_PLACE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'CO_PRIX')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_CARRIERE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_CARRIERE_Q')\n",
    "    test_x = lecture_data.my_drop(test_x, 'pAR_JOC_RAPPORT_GAGNANT_M')\n",
    "    test_x = lecture_data.my_drop(test_x, 'pAR_JOC_REUSSITE_GAGNE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'pAR_JOC_VICTOIRE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_PLACE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_PLACE_Q')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_CLASSE_AGE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'pAR_JOC_VICTOIRE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_REUSSITE_3P')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_JOC_REU_PLACE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_NUM')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_COTEDER')\n",
    "    test_x = lecture_data.my_drop(test_x, 'musique')\n",
    "    test_x = lecture_data.my_drop(test_x, 'Nb_partant')\n",
    "\n",
    "    test_x = lecture_data.my_drop(test_x, 'autostart')\n",
    "    test_x = lecture_data.my_drop(test_x, 'grande_piste')\n",
    "    test_x = lecture_data.my_drop(test_x, 'cendre')\n",
    "\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_PROPRIO')\n",
    "    test_x = lecture_data.my_drop(test_x, 'NOM_JOC')\n",
    "    test_x = lecture_data.my_drop(test_x, 'NOM_ENTR')\n",
    "\n",
    "    test_x = lecture_data.my_drop(test_x, 'HIPPO')\n",
    "    test_x = lecture_data.my_drop(test_x, 'PAR_AGE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'POIDS')\n",
    "    test_x = lecture_data.my_drop(test_x, 'CO_DISTANCE')\n",
    "    test_x = lecture_data.my_drop(test_x, 'CO_PRIX')\n",
    "\n",
    "    #print(\"test_x\",test_x.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #print(test_x)\n",
    "\n",
    "\n",
    "    test_x['v0'] = 0.0\n",
    "    test_x['v1'] = 0.0\n",
    "    test_x['sel'] = 0\n",
    "    #   print(\"test_x\", test_x.shape)\n",
    "    # test_x\n",
    "    cumul = 1\n",
    "    nb_rows = len(df_proba.index)\n",
    "    print(\"nb_rows=\", nb_rows)\n",
    "\n",
    "    for i in range(0, nb_rows):\n",
    "        n = df_proba[0][i]\n",
    "        test_x['v0'][i] = n\n",
    "\n",
    "        n = df_proba[1][i]\n",
    "        test_x['v1'][i] = n\n",
    "\n",
    "\n",
    "    #print(\"test_x\",test_x.shape)\n",
    "\n",
    "   # print(\"\\n\\nTEST_X\\n\")\n",
    "   # print(test_x.head())\n",
    "\n",
    "    if (allure == 1):\n",
    "        test_x.to_csv(\"d:\\py_resultat_trot.csv\")\n",
    "\n",
    "    if (allure == 2):\n",
    "        test_x.to_csv(\"d:\\py_resultat_galop.csv\")\n",
    "\n",
    "    if (allure == 3):\n",
    "        test_x.to_csv(\"d:\\py_resultat_trot_monte.csv\")\n",
    "\n",
    "    if (allure == 4):\n",
    "        test_x.to_csv(\"d:\\py_resultat_haie.csv\")\n",
    "\n",
    "    if (allure == 5):\n",
    "        test_x.to_csv(\"d:\\py_resultat_steeple.csv\")\n",
    "\n",
    "    elapsed = my_timer.get_time()\n",
    "\n",
    "    print(\"\\nTemps de calcul de la construction du fichier  est : %s\" % elapsed)\n",
    "\n",
    "    print(\"\\n\\n ALLER DANS APPLICATION DIABOLO ....\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entraine_allure(allure, nb_iter,mode_debug=0, actualise=0):\n",
    "    # URE DATA\n",
    "    print('---------------------ALLURE(  %s  )------------------------------------------------' % allure)\n",
    "    # Le fichier est lu meme si on  a le best model\n",
    "    df_gagnant, n_features, feature_columns, response_column = calul_data_allure(allure_etudier = allure,mode_debug=mode_debug)\n",
    "\n",
    "\n",
    "    if actualise==0:\n",
    "\n",
    "        #estimateur = GradientBoostingClassifier\n",
    "        estimateur = XGBClassifier\n",
    "        taille_training = 0.85\n",
    "        train_x, test_x, train_y, test_y = my_split(df=df_gagnant,\n",
    "                                                                              taille_entrainement=taille_training,\n",
    "                                                                              feature_columns =feature_columns,\n",
    "                                                                              response_column =response_column,\n",
    "                                                                               random_state=42,\n",
    "                                                                               mode_debug=mode_debug)\n",
    "        #best_model= analyse.fit_xg(X_train=train_x, y_train=train_y, X_test =test_x,y_test=test_y)\n",
    "        best_model = my_fit(estimateur=estimateur,\n",
    "                                        nb_iter=nb_iter, my_nb_splits=10,\n",
    "                                       my_test_size=1 - taille_training,\n",
    "                                        my_random_state=0,\n",
    "                                        train_x=train_x, train_y=train_y,allure=allure,featurecolums=feature_columns)\n",
    "\n",
    "\n",
    "\n",
    "        Plot_predictor_importance(best_model, feature_columns)\n",
    "\n",
    "\n",
    "\n",
    "        # sauvegarde du modele\n",
    "        save_mymodel(clf=best_model,allure=allure)\n",
    "\n",
    "        # EVALUATION\n",
    "        evaluation(mybest_model=best_model, train_x=train_x, test_x=test_x,\n",
    "                           train_y=train_y, test_y=test_y, mode_debug=mode_debug)\n",
    "\n",
    "    else:\n",
    "        # CHARGEMENT DU MODELE\n",
    "        best_model = load_mymodel(allure)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return best_model, feature_columns, response_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jouerlescourse(nb_itera, allure, mode_debug=0, actualise=0):\n",
    "    \n",
    "    global best_model_1,   best_model_2, best_model_3, best_model_4, best_model_5,\\\n",
    "            feature_columns1, feature_columns2, feature_columns3,\\\n",
    "    feature_columns4,      feature_columns5,response_column\n",
    "    \n",
    "    #ENTRAINE_ALLURE\n",
    "    best_model, feature_columns, response_column = entraine_allure(allure=allure,nb_iter=nb_itera,mode_debug=mode_debug,actualise=actualise)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if allure==1:\n",
    "        best_model_1 = best_model\n",
    "        feature_columns1 = feature_columns\n",
    "        \n",
    "    if allure==2:\n",
    "        best_model_2 = best_model\n",
    "        feature_columns2 = feature_columns\n",
    "        \n",
    "    if allure==3:\n",
    "        best_model_3 = best_model\n",
    "        feature_columns3 = feature_columns\n",
    "        \n",
    "    if allure==4:\n",
    "        best_model_4 = best_model\n",
    "        feature_columns4 = feature_columns\n",
    "        \n",
    "    if allure==5:\n",
    "        best_model_5 = best_model\n",
    "        feature_columns5 = feature_columns\n",
    "        \n",
    "            \n",
    "    jouer.construireFichierCSV(allure=allure , best_model=best_model, \n",
    "                                      feature_columns=feature_columns,  \n",
    "                                        response_column=response_column,\n",
    "                                       mode_debug=mode_debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------ALLURE(  1  )------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "nb=1# NB ITERATION=actua)\n",
    "\n",
    "mode_debug=0 # MODE DEBUG\n",
    "actua=0# recalcul du model 0 = actua   1=pas actuia\n",
    "\n",
    "\n",
    "jouerlescourse(nb_itera=nb, allure=1, mode_debug=mode_debug,actualise=actua)\n",
    "jouerlescourse(nb_itera=nb, allure=2,mode_debug=mode_debug,actualise=actua)\n",
    "jouerlescourse(nb_itera=nb, allure=3, mode_debug=mode_debug,actualise=actua)\n",
    "jouerlescourse(nb_itera=nb, allure=4, mode_debug=mode_debug,actualise=actua)\n",
    "jouerlescourse(nb_itera=nb, allure=5, mode_debug=mode_debug,actualise=actua)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
