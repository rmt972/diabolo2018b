{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIABOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "allure_etudier=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries needed for the tutorial\n",
    "\n",
    "# General syntax to import specific functions in a library: \n",
    "##from (library) import (specific library function)\n",
    "#from  pandas import DataFrame, read_csv\n",
    "\n",
    "# General syntax to import a library but no functions: \n",
    "##import (library) as (give the library a nickname/alias)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import sklearn\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error, cohen_kappa_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve, SCORERS\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import *\n",
    "\n",
    "import graphviz as gv\n",
    "\n",
    "import pydotplus\n",
    "import io\n",
    "from scipy import misc\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Operating system version....', platform.platform())\n",
    "print(\"Python version is........... %s.%s.%s\" % sys.version_info[:3])\n",
    "print('scikit-learn version is.....', sklearn.__version__)\n",
    "print('pandas version is...........', pd.__version__)\n",
    "print('numpy version is............', np.__version__)\n",
    "print('matplotlib version is.......', matplotlib.__version__)\n",
    "print('scipy version is.......', scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins for the win column\n",
    "def assign_selection(W):\n",
    "    \n",
    "    if W >=1 and W <=3:\n",
    "        return 1\n",
    "    if W >3:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "procedure"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def CorrelationDesVariable(df_gagnant):\n",
    "    \n",
    "    fig2, ax = plt.subplots(figsize=(20,20))\n",
    "    sns.heatmap(df_gagnant.corr(), annot=True, fmt=\".2f\", linewidths=0.5, ax=ax)\n",
    "    plt.show()\n",
    "    \n",
    "    #--------------------------SEPARATION DES DONNES------------------------------\n",
    "def split_dataset(dataset, train_percentage, feature_headers, target_header):\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(dataset[feature_headers],  dataset[target_header],\n",
    "                                                        train_size=train_percentage, random_state=42)\n",
    "     # Train and Test dataset size details\n",
    "    print(\"--------------------------------\")    \n",
    "    print (\"Train_x Shape :: \", train_x.shape)    \n",
    "    print (\"Train_y Shape :: \", train_y.shape)\n",
    "    print (\"Test_x Shape :: \", test_x.shape)    \n",
    "    print (\"Test_y Shape :: \", test_y.shape)\n",
    "    print(\"--------------------------------\")\n",
    "    \n",
    "    \n",
    "    return train_x, test_x, train_y, test_y\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "def lecture_data(Fichier, xnames, xindex_col):\n",
    "    \n",
    "                    df=pd.read_csv (Fichier,\n",
    "                                       index_col=xindex_col, \n",
    "                                       sep=';',\n",
    "                                       names=xnames,skipinitialspace=True,\n",
    "                                       encoding='Latin-1' )\n",
    "                        \n",
    "       \n",
    "                    #Suppression de la collone TROT\n",
    "                    df.drop([\"FIN_ligne\"], axis=1, inplace=True)\n",
    "                    #Suppression de la collone TROT\n",
    "                    df.drop([\"PAR_NP\"], axis=1, inplace=True)\n",
    "                    #Suppression de la collone TROT\n",
    "                 #   df.drop([\"PAR_COTEDER\"], axis=1, inplace=True)\n",
    "                    #Suppression de la collone TROT\n",
    "                    df.drop([\"cendre\"], axis=1, inplace=True)\n",
    "                    #Suppression de la collone TROT\n",
    "                    ##df.drop([\"autostart\"], axis=1, inplace=True)\n",
    "                    #Suppression de la collone TROT\n",
    "                    df.drop([\"grande_piste\"], axis=1, inplace=True)\n",
    "                    df.drop([\"CO_DISTANCE\"], axis=1, inplace=True)\n",
    "                    df.drop([\"musique\"], axis=1, inplace=True)\n",
    "                    \n",
    "                    #df.drop([\"PAR_CLASSE_AGE\"], axis=1, inplace=True)\n",
    "                    #df.drop([\"PAR_ENT_ECART_GAGNANT\"], axis=1, inplace=True)\n",
    "                   # df.drop([\"PAR_ENT_RAPPORT_GAGNANT_M\"], axis=1, inplace=True)\n",
    "                    #df.drop([\"PAR_ENT_VICTOIRE\"], axis=1, inplace=True)\n",
    "                    #df.drop([\"PAR_GAIN\"], axis=1, inplace=True)\n",
    "                    \n",
    "                    #df.drop([\"PAR_CARRIERE_Q\"], axis=1, inplace=True)\n",
    "                    #df.drop([\"PAR_ENT_REU_PLACE\"], axis=1, inplace=True)\n",
    "                    #df.drop([\"PAR_ENT_REUSSITE_GAGNE\"], axis=1, inplace=True)\n",
    "                    \n",
    "                   # df.drop([\"pAR_JOC_ECART_GAGNANT\"], axis=1, inplace=True)\n",
    "                    #df.drop([\"PAR_JOC_ECART_PLACE\"], axis=1, inplace=True)\n",
    "                    #df.drop([\"PAR_JOC_NB_COURSE\"], axis=1, inplace=True)\n",
    "                    #df.drop([\"CO_PRIX\"], axis=1, inplace=True)\n",
    "                    #df.drop([\"PAR_CARRIERE\"], axis=1, inplace=True)\n",
    "                    #df.drop([\"PAR_CARRIERE_Q\"], axis=1, inplace=True)\n",
    "                   # df.drop([\"pAR_JOC_RAPPORT_GAGNANT_M\"], axis=1, inplace=True)\n",
    "                \n",
    "                    df.drop([\"PAR_COTEDER\"], axis=1, inplace=True)\n",
    "                    #df.drop([\"Nb_partant\"], axis=1, inplace=True)\n",
    "                    df.drop([\"autostart\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    return df \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_drop(df,col):\n",
    "    if col in df:\n",
    "        df.drop([col], axis=1, inplace=True)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#mms=StandardScaler()\n",
    "#train_x=mms.fit_transform(train_x)\n",
    "#test_x=mms.transform(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir une classe TIme au temps d'exécution total de l'ordinateur\n",
    "class Timer:\n",
    "  def __init__(self):\n",
    "    self.start = time.time()\n",
    "\n",
    "  def restart(self):\n",
    "    self.start = time.time()\n",
    "\n",
    "  def get_time(self):\n",
    "    end = time.time()\n",
    "    m, s = divmod(end - self.start, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    time_str = \"%02d:%02d:%02d\" % (h, m, s)\n",
    "    return time_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=20):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "          \n",
    "            print(\"\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définir une méthode pour imprimer la matrice de confusion et les indicateurs de performance\n",
    "def Print_confusion_matrix(cm, auc, heading):\n",
    "    print('\\n', heading)\n",
    "    print(cm)\n",
    "    true_negative  = cm[0,0]\n",
    "    true_positive  = cm[1,1]\n",
    "    false_negative = cm[1,0]\n",
    "    false_positive = cm[0,1]\n",
    "    total = true_negative + true_positive + false_negative + false_positive\n",
    "    accuracy = (true_positive + true_negative)/total\n",
    "    precision = (true_positive)/(true_positive + false_positive)\n",
    "    recall = (true_positive)/(true_positive + false_negative)\n",
    "    misclassification_rate = (false_positive + false_negative)/total\n",
    "    F1 = (2*true_positive)/(2*true_positive + false_positive + false_negative)\n",
    "    print('accuracy.................%7.4f' % accuracy)\n",
    "    print('precision................%7.4f' % precision)\n",
    "    print('recall...................%7.4f' % recall)\n",
    "    print('F1.......................%7.4f' % F1)\n",
    "    print('auc......................%7.4f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définir une fonction d'utilité pour signaler les meilleurs scores\n",
    "def Report_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définir une méthode pour tracer l'importance du prédicteur\n",
    "def Plot_predictor_importance(best_model, feature_columns):\n",
    "    feature_importance = best_model.feature_importances_\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    y_pos  = np.arange(sorted_idx.shape[0]) + .6\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.barh(y_pos, \n",
    "            feature_importance[sorted_idx], \n",
    "            align='center', \n",
    "            color='green', \n",
    "            ecolor='black', \n",
    "            height=0.5)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(feature_columns)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Relative Importance')\n",
    "    ax.set_title('Predictor Importance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# hyper parametres + Construction de l'estimateur + RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_randomize_estimateur(estimateur, nb_iteration):\n",
    "\n",
    "    if (estimateur==RandomForestClassifier):\n",
    "            param_dist = {\"n_estimators\": range(20, 100, 2),\n",
    "                \n",
    "                  \"min_samples_leaf\": range(50, 2500, 2),\n",
    "                  \"max_features\": [None, 2,3, 4,5, 6,7, 8, 9,10,11, 12,13, 14],\n",
    "                  \"min_samples_split\": sp_randint(2, 2000),\n",
    "                  \"bootstrap\": [True, False],\n",
    "                  \"criterion\": [\"gini\", \"entropy\"]}   \n",
    "            \n",
    "            clf=RandomForestClassifier(class_weight = 'balanced')\n",
    "            \n",
    "            estimator=RandomizedSearchCV(clf,\n",
    "                                   param_distributions = param_dist,\n",
    "                                   n_iter = nb_iteration,\n",
    "                                   scoring = 'roc_auc',\n",
    "                                   verbose = 2,\n",
    "                                   n_jobs = 1)    \n",
    "\n",
    "    if (estimateur==GradientBoostingClassifier):\n",
    "            param_dist = {\"loss\": [\"deviance\", \"exponential\"],\n",
    "            \"min_samples_split\": [500,1000,1500,2000,2500,3500,4000],\n",
    "            \"min_samples_leaf\": range(50, 2500, 2),\n",
    "             \"learning_rate\":[ 1,0.5,0.05],              \n",
    "           # \"min_weight_fraction_leaf\" : [0.10,0.20,0.30,0.40,0.50,0.60],            \n",
    "            \"max_depth\":[3,5,8,10,13,15,18, 20,25],\n",
    "            \"max_features\": [None,0.10,0.20,0.30,0.40,0.50,0.60,0.70],            \n",
    "            \"criterion\": [\"friedman_mse\", \"mse\"]}\n",
    "                # CONSTRUCTION DU CLASSIFICATEUR\n",
    "                \n",
    "            clf = GradientBoostingClassifier()                                \n",
    "            \n",
    "            estimator=RandomizedSearchCV(clf, param_distributions = param_dist, \n",
    "                                         scoring = 'roc_auc', verbose = 1,\n",
    "                                         n_iter = nb_iteration, n_jobs = 1)    \n",
    "            \n",
    "            \n",
    "    return estimator\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_learning_curve(estimator, \n",
    "                        title, X, y, \n",
    "                        ylim = None, \n",
    "                        cv = None,\n",
    "                        n_jobs = 1, \n",
    "                        train_sizes = np.linspace(0.1, 1.0, 5)):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, \n",
    "                                                            X, y,\n",
    "                                                            cv = cv,\n",
    "                                                            n_jobs = n_jobs,\n",
    "                                                            train_sizes = train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_split(taille_entrainement):\n",
    "  \n",
    "    \n",
    "    train_x, test_x, train_y, test_y = split_dataset(df_gagnant, taille_entrainement, feature_columns, response_column)    \n",
    "    return  train_x, test_x, train_y, test_y     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calul_data_allure(allure_etudier):\n",
    "    global df_gagnant,n_features,feature_columns,response_column\n",
    "    \n",
    "    #lecture des données\n",
    "    xnames=['ALLURE'\n",
    "                    ,'CO_DISTANCE',\n",
    "                    'CO_PRIX',\n",
    "                    'IDCOURSE',\n",
    "                    'IDPARTCIPANT',\n",
    "                    'PAR_ARRIVE',\n",
    "                    'PAR_CARRIERE',\n",
    "                    'PAR_CARRIERE_Q' ,\n",
    "                    'PAR_CLASSE_AGE',\n",
    "                    'PAR_COTEDER',\n",
    "                    'PAR_ENT_ECART_GAGNANT',\n",
    "                    'PAR_ENT_RAPPORT_GAGNANT_M',\n",
    "                    'PAR_ENT_REU_PLACE',\n",
    "                    'PAR_ENT_REUSSITE_GAGNE',\n",
    "                    'PAR_ENT_VICTOIRE',\n",
    "                    'PAR_GAIN',\n",
    "                    'pAR_JOC_ECART_GAGNANT',\n",
    "                    'PAR_JOC_ECART_PLACE',\n",
    "                    'PAR_JOC_NB_COURSE',\n",
    "                    'PAR_JOC_PLACE_3P',\n",
    "                    'pAR_JOC_RAPPORT_GAGNANT_M',\n",
    "                    'PAR_JOC_REU_PLACE',\n",
    "                    'pAR_JOC_REUSSITE_GAGNE',\n",
    "                    'pAR_JOC_VICTOIRE',\n",
    "                    'PAR_NP',\n",
    "                    'PAR_NUM',\n",
    "                    'PAR_PLACE',\n",
    "                    'PAR_PLACE_Q',\n",
    "                    'PAR_REUSSITE_3P',\n",
    "                    'PAR_REUSSITE_GAGNE',\n",
    "                    'PAR_REUSSITE_QUINTE',\n",
    "                    'PAR_RUESSITE_PLACE',\n",
    "                    'autostart',\n",
    "                    'cendre',\n",
    "                    'grande_piste',\n",
    "                    'Point',\n",
    "                    'Nb_partant','musique','FIN_ligne']\n",
    "    \n",
    "    df=lecture_data('d:\\diabollo_al_1.csv',xnames,['IDPARTCIPANT','IDCOURSE','PAR_NUM'])\n",
    "    \n",
    "    # groupage par allure\n",
    "    df=df.groupby(\"ALLURE\")     \n",
    "    df=df.get_group(allure_etudier)\n",
    "    df.head()\n",
    "    df=my_drop(df,'ALLURE')\n",
    "    # Shape des données\n",
    "    print(\" df \",df.shape)\n",
    "    print(\"\")\n",
    "    # Contruction de df_gagant\n",
    "    df_gagnant = df\n",
    "    \n",
    "    # les lignes sans GAIN sont éliminées\n",
    "    df_gagnant=df_gagnant[df_gagnant.PAR_GAIN >1000] # On garde les lignes avec GAIN\n",
    "    df_gagnant=df_gagnant[df_gagnant.PAR_GAIN <900000] # On garde les lignes avec GAIN\n",
    "    \n",
    "    #les lignes sans arrivée n'apportent rien !!!!\n",
    "    df_gagnant=df_gagnant[df_gagnant.PAR_ARRIVE>0] # On garde la ligne qui possede information arrivée        \n",
    "    \n",
    "    # Shape des données df_gagant\n",
    "    print(\" df_gagnant \",df_gagnant.shape)\n",
    "    print(\"Features\")\n",
    "    print(\"\")\n",
    "    COLUM=df_gagnant.columns\n",
    "    print(COLUM)\n",
    "    \n",
    "    #Construction de la cible\n",
    "    df_gagnant['SELECTION'] = df_gagnant['PAR_ARRIVE'].apply(assign_selection)\n",
    "    \n",
    "    #Suppression de la colonne qui a permis de construire la cible : PAR_ARRIVE\n",
    "    df_gagnant_len=len(df_gagnant)\n",
    "    df_gagnant.drop([\"PAR_ARRIVE\"], axis=1, inplace=True)\n",
    "    print(\"df_gagnant\",df_gagnant.shape) # description de l'ensemble\n",
    "    print(\"\")\n",
    "    # DECSCRIPTION  ************\n",
    "    # FEATURE\n",
    "    # CIBLE\n",
    "    #pd.DataFrame.hist(df_gagnant, figsize = [15,15]);\n",
    "    \n",
    "    df_gagnant_len=len(df_gagnant.columns)-1\n",
    "    \n",
    "    Lib_features = list(df_gagnant.columns[:df_gagnant_len]) # Liebllé des variable DATA\n",
    "    #feature_columns=[\"Point\",\"PAR_RUESSITE_PLACE\",\"PAR_REUSSITE_QUINTE\",\"PAR_ENT_REUSSITE_GAGNE\",\"PAR_REUSSITE_3P\",\"PAR_PLACE_Q\",\"PAR_PLACE\",\"pAR_JOC_VICTOIRE\"]\n",
    "    feature_columns = Lib_features\n",
    "    print(\"FEATURES :  \",Lib_features,\" <<<<************\")\n",
    "    print(\"\")\n",
    "    \n",
    "    #---------------------------------------------------\n",
    "    n_features =len(feature_columns)\n",
    "    print(\"NOMBRE DE FEATURE :\",n_features)\n",
    "    \n",
    "    #---------------------------------------------------\n",
    "    \n",
    "    response_column = ['SELECTION']\n",
    "    \n",
    "    print(\"Colonne cible :\",response_column)\n",
    "    print(\"C'est la donnée a predire\")\n",
    "    \n",
    "    \n",
    "    return df_gagnant\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fit(estimateur, nb_iter, my_nb_splits, my_test_size, my_random_state,train_x,train_y):\n",
    "    \n",
    "    global cv_\n",
    "    \n",
    "    print(\"\\n MY FIT\")\n",
    "    estimator=my_randomize_estimateur(estimateur,nb_iter)\n",
    "    #fit = estimator.fit(train_x,train_y[\"SELECTION\"].ravel(),sample_weight=np.ones(len(train_y)))\n",
    "    \n",
    "    \n",
    "    fit = estimator.fit(train_x,train_y[\"SELECTION\"].ravel())\n",
    "    print(\"\\n fit terminé\")\n",
    "    #cross validation\n",
    "    cv_ = ShuffleSplit(n_splits = my_nb_splits, test_size = my_test_size, random_state = my_random_state)\n",
    "    print(\"\\n ShuffleSplit\")\n",
    "    Report_scores(estimator.cv_results_, n_top = 3)\n",
    "    \n",
    "    print(\"\\n Report Scores\\n\")\n",
    "    best_model = estimator.best_estimator_\n",
    "    \n",
    "    print('\\nbest_model:\\n', best_model)\n",
    "    print('\\nbest_model Nombre de Feature: ', best_model.n_features_)\n",
    "    #print('best_model  Nombre de sorties : ', best_model.n_outputs_)\n",
    "    print('best_model  Classes : ', best_model.classes_)\n",
    "    print('\\nbest_model  importance des features : ', best_model.feature_importances_)\n",
    "    print(\"\")\n",
    "    print(\"IMPORTANCE DES CRITERES **********************\")\n",
    "    Plot_predictor_importance(best_model, feature_columns)\n",
    "    \n",
    "    \n",
    "    print(\"PLOT LEARNING CURVE\\n .....\")    \n",
    "    Plot_learning_curve(estimator,\"evaluation training\",train_x,train_y[\"SELECTION\"].ravel(),ylim=None)#cv=cv_)\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(mybest_model,train_x, test_x, train_y, test_y):\n",
    "    print(\" EVALUATION********TRAINING Set*********\")\n",
    "    y_predicted = mybest_model.predict(train_x)\n",
    "    probabilities = mybest_model.predict_proba(train_x)\n",
    "    c_report = classification_report(train_y, y_predicted)\n",
    "    print('\\nClassification report TRAINING:\\n', c_report)\n",
    "\n",
    "    \n",
    "    print(\"\\n EVALUATION*******TEST Set*********\")\n",
    "    y_predicted = mybest_model.predict(test_x)\n",
    "    probabilities = mybest_model.predict_proba(test_x)\n",
    "    c_report = classification_report(test_y, y_predicted)\n",
    "    print('\\nClassification report TEST:\\n', c_report)\n",
    "    \n",
    "    \n",
    "    auc = roc_auc_score(test_y, y_predicted)\n",
    "    print(\"roc_auc_score :  \",auc)    \n",
    "    cm = confusion_matrix(test_y, y_predicted.ravel())\n",
    "    print(\"\")\n",
    "    Print_confusion_matrix(cm, auc, 'Confusion matrics of the TEST dataset')\n",
    "    \n",
    "    print(\"Confusion matrix\\n\")\n",
    "    \n",
    "    #print(\"CM\",cm)\n",
    "    #from sklearn.metrics import confusion_matrix\n",
    "    for x,y in [ (train_x, train_y), (test_x, test_y) ]:\n",
    "        yp  = mybest_model.predict(x)\n",
    "        cm = confusion_matrix(y, yp.ravel())\n",
    "    #print(cm)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.matshow(cm)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    print(\"\")\n",
    "    ntotal = len(test_y)\n",
    "    correct = test_y[\"SELECTION\"].ravel() == y_predicted\n",
    "    numCorrect = sum(correct)\n",
    "    percent = round( (100.0*numCorrect)/ntotal, 6)\n",
    "    print(\"\\n CLASSIFICATION CORRECTE DES DONNEES DE TEST : {0:d}/{1:d} {2:8.3f}%\".format(numCorrect, ntotal, percent))\n",
    "    prediction_score = 100.0*mybest_model.score(test_x, test_y)\n",
    "    print('Score de RANDOM Forest Prediction Score sur données de test : %8.3f' % prediction_score)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entraine_allure(allure, nb_iter):\n",
    "    \n",
    "    global best_model_1,best_model_2,best_model_3\n",
    "    #definir le dataframe DF_GAGNANT\n",
    "    # global df_gagnant,n_features,feature_columns,response_column\n",
    "    # defini dans calcul_allure\n",
    "    df_gagnant=calul_data_allure(allure_etudier=1)\n",
    "\n",
    "    #SPLIT des DONNEES\n",
    "    Taille_training=0.85\n",
    "    train_x, test_x, train_y, test_y =my_split(Taille_training)\n",
    "    from sklearn.utils.class_weight import compute_sample_weight\n",
    "    y = train_y\n",
    "    res=compute_sample_weight(class_weight='balanced', y=y)\n",
    "    print(\"compute_sample_weight\",res)\n",
    "    \n",
    "    # FIT\n",
    "    best_model=my_fit(estimateur=GradientBoostingClassifier,nb_iter=nb_iter,\n",
    "                             my_nb_splits=40,\n",
    "                             my_test_size=1-Taille_training,\n",
    "                             my_random_state=42,train_x=train_x,train_y=train_y)\n",
    "    \n",
    "    #Evaluation des set\n",
    "    print(\"evaluation des set\")\n",
    "    evaluation(best_model,train_x, test_x, train_y, test_y )\n",
    "    \n",
    "    # gestion des modeles par allure\n",
    "    if allure==1:\n",
    "        best_model_1=best_model\n",
    "    if allure==2:\n",
    "        best_model_2=best_model    \n",
    "    if allure==3:\n",
    "        best_model_3=best_model       \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construireFichierCSV(allure,best_model):\n",
    "    #lecture des données a jouer\n",
    "    xnames=['ALLURE'\n",
    "                    ,'CO_DISTANCE',\n",
    "                    'CO_PRIX',\n",
    "                    'IDCOURSE',\n",
    "                    'IDPARTCIPANT',\n",
    "                    'PAR_ARRIVE',\n",
    "                    'PAR_CARRIERE',\n",
    "                    'PAR_CARRIERE_Q' ,\n",
    "                    'PAR_CLASSE_AGE',\n",
    "                    'PAR_COTEDER',\n",
    "                    'PAR_ENT_ECART_GAGNANT',\n",
    "                    'PAR_ENT_RAPPORT_GAGNANT_M',\n",
    "                    'PAR_ENT_REU_PLACE',\n",
    "                    'PAR_ENT_REUSSITE_GAGNE',\n",
    "                    'PAR_ENT_VICTOIRE',\n",
    "                    'PAR_GAIN',\n",
    "                    'pAR_JOC_ECART_GAGNANT',\n",
    "                    'PAR_JOC_ECART_PLACE',\n",
    "                    'PAR_JOC_NB_COURSE',\n",
    "                    'PAR_JOC_PLACE_3P',\n",
    "                    'pAR_JOC_RAPPORT_GAGNANT_M',\n",
    "                    'PAR_JOC_REU_PLACE',\n",
    "                    'pAR_JOC_REUSSITE_GAGNE',\n",
    "                    'pAR_JOC_VICTOIRE',\n",
    "                    'PAR_NP',\n",
    "                    'PAR_NUM',\n",
    "                    'PAR_PLACE',\n",
    "                    'PAR_PLACE_Q',\n",
    "                    'PAR_REUSSITE_3P',\n",
    "                    'PAR_REUSSITE_GAGNE',\n",
    "                    'PAR_REUSSITE_QUINTE',\n",
    "                    'PAR_RUESSITE_PLACE',\n",
    "                    'autostart',\n",
    "                    'cendre',\n",
    "                    'grande_piste',\n",
    "                    'Point',\n",
    "                    'Nb_partant','musique','FIN_ligne']\n",
    "    df_numero_a_predire=lecture_data('d:\\diabollo_al_1_D.csv',xnames,['IDPARTCIPANT','IDCOURSE','PAR_NUM'])    \n",
    "    #print(\" df_numero_a_predire \",df_numero_a_predire.shape)\n",
    "    df_numero_a_predire=df_numero_a_predire.groupby(\"ALLURE\") \n",
    "    df_numero_a_predire=df_numero_a_predire.get_group(allure) \n",
    "    \n",
    "    #suppression des features inutiles\n",
    "    df_numero_a_predire=my_drop(df_numero_a_predire,'ALLURE')\n",
    "    df_numero_a_predire=my_drop(df_numero_a_predire,'PAR_ARRIVE')\n",
    "    \n",
    "    #df_numero_a_predire.head()\n",
    "    \n",
    "    df_numero_a_predire['SELECTION'] =0\n",
    "    train_x, test_x, train_y, test_y = split_dataset(df_numero_a_predire, 0, feature_columns, response_column)   \n",
    "    #sauvegarde\n",
    "    test_copy = test_x.copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    y_pred=best_model.predict(test_x)\n",
    "    \n",
    "    df_pred = pd.DataFrame.from_dict(y_pred)\n",
    "    \n",
    "    #print(df_pred)\n",
    "    print(\"PREDICTION COURSES A JOUER\")\n",
    "    print(y_pred)\n",
    "          \n",
    "    # UTILISATION DE BEST_MODEL      \n",
    "    PROBA=best_model.predict_proba(test_x)\n",
    "    df_proba = pd.DataFrame.from_dict(PROBA)\n",
    "          \n",
    "    print(\"df final=\")     \n",
    "    df_final =pd.concat([df_proba,df_pred], axis=1)\n",
    "   # print(df_final.head())\n",
    "     \n",
    "    test_x = test_copy.copy()     \n",
    "\n",
    "    test_x=my_drop(test_x,'PAR_CLASSE_AGE')\n",
    "    test_x=my_drop(test_x,'PAR_ENT_ECART_GAGNANT')\n",
    "    test_x=my_drop(test_x,'PAR_ENT_RAPPORT_GAGNANT_M')\n",
    "    test_x=my_drop(test_x,'PAR_ENT_REU_PLACE')\n",
    "    test_x=my_drop(test_x,'PAR_ENT_REUSSITE_GAGNE')\n",
    "    test_x=my_drop(test_x,'PAR_ENT_VICTOIRE')\n",
    "    test_x=my_drop(test_x,'PAR_GAIN')\n",
    "    test_x=my_drop(test_x,'pAR_JOC_ECART_GAGNANT')\n",
    "    test_x=my_drop(test_x,'PAR_JOC_ECART_PLACE')\n",
    "    test_x=my_drop(test_x,'PAR_JOC_NB_COURSE')\n",
    "    test_x=my_drop(test_x,'PAR_JOC_PLACE_3P')\n",
    "    test_x=my_drop(test_x,'PAR_REUSSITE_GAGNE')\n",
    "    test_x=my_drop(test_x,'PAR_REUSSITE_QUINTE')\n",
    "    test_x=my_drop(test_x,'PAR_RUESSITE_PLACE')\n",
    "    test_x=my_drop(test_x,'CO_PRIX')\n",
    "    test_x=my_drop(test_x,'PAR_CARRIERE')\n",
    "    test_x=my_drop(test_x,'PAR_CARRIERE_Q')\n",
    "    test_x=my_drop(test_x,'pAR_JOC_RAPPORT_GAGNANT_M')\n",
    "    test_x=my_drop(test_x,'pAR_JOC_REUSSITE_GAGNE')\n",
    "    test_x=my_drop(test_x,'pAR_JOC_VICTOIRE')\n",
    "    test_x=my_drop(test_x,'PAR_PLACE')\n",
    "    test_x=my_drop(test_x,'PAR_PLACE_Q')\n",
    "    test_x=my_drop(test_x,'PAR_CLASSE_AGE')\n",
    "    test_x=my_drop(test_x,'pAR_JOC_VICTOIRE')\n",
    "    test_x=my_drop(test_x,'PAR_REUSSITE_3P')\n",
    "    test_x=my_drop(test_x,'PAR_JOC_REU_PLACE')\n",
    "    test_x=my_drop(test_x,'PAR_COTEDER')\n",
    "    test_x=my_drop(test_x,'musique')\n",
    "    test_x=my_drop(test_x,'Nb_partant')\n",
    "    test_x.head(10)\n",
    "          \n",
    "          \n",
    "    test_x['v0']=0.0\n",
    "    test_x['v1']=0.0\n",
    "    test_x['sel']=0\n",
    "    #test_x     \n",
    "    cumul=1\n",
    "    nb_rows=len(df_proba.index)\n",
    "\n",
    "    for i in range(0,nb_rows):\n",
    "            n=df_proba[0][i]\n",
    "            test_x['v0'][i]=n    \n",
    "            n=df_proba[1][i]\n",
    "            test_x['v1'][i]=n      \n",
    "     \n",
    "    print(test_x.head())\n",
    "    \n",
    "    \n",
    "    if (allure==1):\n",
    "        test_x.to_csv(\"d:\\py_resultat_trot.csv\")  \n",
    "    \n",
    "    if (allure==2):\n",
    "        test_x.to_csv(\"d:\\py_resultat_galop.csv\")  \n",
    "    \n",
    "    if (allure==3):\n",
    "        test_x.to_csv(\"d:\\py_resultat_trot_monte.csv\")  \n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"\\n\\n ALLER DANS APPLICATION DIABOLO ....\")\n",
    "          \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------- CALCULER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------------TROT-------------------------------------------------\")\n",
    "my_timer = Timer()\n",
    "# creation de best_model_1\n",
    "entraine_allure(allure=1,nb_iter=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"-----------------------GALOP-------------------------------------------------\")\n",
    "\n",
    "# creation de best_model_2\n",
    "#entraine_allure(allure=2,nb_iter=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"-----------------------MONTE-------------------------------------------------\")\n",
    "\n",
    "# creation de best_model_3\n",
    "#entraine_allure(allure=3, nb_iter=1)\n",
    "\n",
    "elapsed = my_timer.get_time()\n",
    "\n",
    "print(\"\\nTemps de calcul du FIT MONTE  est : %s\" % elapsed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "construireFichierCSV(1,best_model_1)\n",
    "construireFichierCSV(2,best_model_2)\n",
    "construireFichierCSV(3,best_model_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#mms=MinMaxScaler()\n",
    "#test_x=mms.fit_transform(test_x)\n",
    "#test_x=mms.transform(test_x)\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#mms=StandardScaler()\n",
    "#test_x=mms.fit_transform(test_x)\n",
    "#test_x=mms.transform(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
