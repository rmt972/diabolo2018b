{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "allure_etudier=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating system version.... Windows-10-10.0.17134-SP0\n",
      "Python version is........... 3.6.5\n",
      "scikit-learn version is..... 0.19.1\n",
      "pandas version is........... 0.22.0\n",
      "numpy version is............ 1.14.2\n",
      "matplotlib version is....... 2.2.0\n",
      "scipy version is....... 1.0.0\n"
     ]
    }
   ],
   "source": [
    "import  sys\n",
    "\n",
    "#LOCALISATION DES DONNEES\n",
    "sys.path.insert(0, \"C:/projets_python/diabolo\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "#LIBRAIRIES PERSO\n",
    "import etude_variable.MyLog as log\n",
    "#import etude_variable.jouer as jouer\n",
    "\n",
    "#import etude_variable.analyse as ana\n",
    "\n",
    "# LIBRAIRIE PYHTON CLASSIQUES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import scipy\n",
    "import platform\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "#ESTIMATEUR\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#MISE A l ECHELLE\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "\n",
    "#TRAINING\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "import dask_searchcv as dcv\n",
    "from skopt.space import Real, Integer\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#Evaluateur\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#outils\n",
    "from dask.diagnostics import ProgressBar\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#Metriques\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn import  metrics\n",
    "from sklearn.metrics import  roc_auc_score\n",
    "from sklearn.metrics import  classification_report\n",
    "\n",
    "#Outils\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "#Graphique\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print('Operating system version....', platform.platform())\n",
    "print(\"Python version is........... %s.%s.%s\" % sys.version_info[:3])\n",
    "print('scikit-learn version is.....', sklearn.__version__)\n",
    "print('pandas version is...........', pd.__version__)\n",
    "print('numpy version is............', np.__version__)\n",
    "print('matplotlib version is.......', matplotlib.__version__)\n",
    "print('scipy version is.......', scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LECTURE DES DONNEES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lecture_data(Fichier, xnames, xindex_col, allure=1, mode_debug=0, avec_index=True):\n",
    "    \n",
    "    print(\"DATA ....\")\n",
    "    start_time=timer()\n",
    "    if avec_index==True:\n",
    "        df = pd.read_csv(Fichier,  index_col=xindex_col,     sep=';',     names=xnames,               skipinitialspace=True,              encoding='Latin-1')\n",
    "    else:\n",
    "        df = pd.read_csv(Fichier,   index_col=None,  sep=';',                     names=xnames,                         skipinitialspace=True,     encoding='Latin-1')\n",
    "\n",
    "    df = df.groupby(\"ALLURE\")\n",
    "    df = df.get_group(allure)\n",
    "    #print(df.info())\n",
    "\n",
    "    print(timer(start_time))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        print(start_time)\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_2(model, train_x, train_y, test_x, test_y):    \n",
    "    from sklearn.feature_selection import RFE\n",
    "    rfc=model\n",
    "    # create the RFE model and select 4 attributes\n",
    "    rfe_model = RFE(rfc, 9, step=1)\n",
    "    rfe_model = rfe_model.fit(train_x, train_y)\n",
    "    # summarize the selection of the attributes\n",
    "    print(rfe_model.support_)\n",
    "    print(rfe_model.ranking_)\n",
    "\n",
    "    # evaluate the model on testing set\n",
    "    pred_y = rfe_model.predict(test_x)\n",
    "    predictions = [round(value) for value in pred_y]\n",
    "    accuracy = accuracy_score(test_y, predictions)\n",
    "    print(\"Test Accuracy: %.2f%%\" % (accuracy*100.0))\n",
    "    print(train_x.mean()   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit speciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fit2(estimateur, train_x, train_y):\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n",
    "    \n",
    "    results = cross_val_score(estimateur, train_x, train_y, cv=kfold)\n",
    "    print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \n",
    "    y_pred = model.predict(test_x)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    return model,y_pred,predictions\n",
    "\n",
    "\n",
    "def fit_special(estimateur,    test_x,test_y, train_x, train_y):\n",
    "    # Use SelectFromModel\n",
    "    thresholds = np.sort(estimateur.best_estimator_.named_steps[\"clf\"].feature_importances_)\n",
    "\n",
    "    for thresh in thresholds:\n",
    "        # select features using threshold\n",
    "        selection = SelectFromModel(estimateur, threshold=thresh, prefit=True)\n",
    "        select_X_train = selection.transform(train_x)\n",
    "\n",
    "        # train model\n",
    "        selection_model = estimateur\n",
    "        selection_model.fit(select_X_train, train_y)\n",
    "\n",
    "        # eval model\n",
    "        select_X_test = selection.transform(test_x)\n",
    "        y_pred = selection_model.predict(select_X_test)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        accuracy = accuracy_score(test_y, predictions)\n",
    "        print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy * 100.0))\n",
    "        print(confusion_matrix(test_y, predictions))\n",
    "        print(classification_report(test_y, predictions))\n",
    "\n",
    "    y_pred = estimateur.predict(test_x)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    return estimateur,y_pred,predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mise_en_relation(df,crit,n):\n",
    "  \n",
    "    print(df_course)\n",
    "    qt=quantile_transform(df.loc[df['IDCOURSE']==n, crit], n_quantiles=20, random_state=0,subsample=25 )\n",
    "    \n",
    "    \n",
    "    return qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sclalerise_course(df):\n",
    "    print(\"Scalerise_course ...\")\n",
    "    start_time=timer()\n",
    "    for n, g in df.groupby('IDCOURSE'):\n",
    "        #df.loc[df['IDCOURSE'] ==n, 'PAR_REUSSITE_3P_'] = quantile_transform(df.loc[df['IDCOURSE']==n, ['PAR_REUSSITE_3P']], n_quantiles=20, random_state=0,subsample=25 )\n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_REUSSITE_3P_'] = mise_en_relation(df,['PAR_REUSSITE_3P'],n)\n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_CARRIERE_'] = mise_en_relation(df,['PAR_CARRIERE'],n)\n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_CARRIERE_Q_'] = mise_en_relation(df,['PAR_CARRIERE_Q'],n)\n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_CLASSE_AGE_'] = mise_en_relation(df,['PAR_CLASSE_AGE'],n)\n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_COTEDER_'] = mise_en_relation(df,['PAR_COTEDER'],n)\n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_ENT_ECART_GAGNANT_'] = mise_en_relation(df,['PAR_ENT_ECART_GAGNANT'],n)\n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_ENT_RAPPORT_GAGNANT_M_'] = mise_en_relation(df,['PAR_ENT_RAPPORT_GAGNANT_M'],n)    \n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_ENT_REU_PLACE_'] = mise_en_relation(df,['PAR_ENT_REU_PLACE'],n)    \n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_ENT_REUSSITE_GAGNE_'] = mise_en_relation(df,['PAR_ENT_REUSSITE_GAGNE'],n)    \n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_ENT_VICTOIRE_'] = mise_en_relation(df,['PAR_ENT_VICTOIRE'],n)    \n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_PLACE_'] = mise_en_relation(df,['PAR_PLACE'],n)  \n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_PLACE_Q_'] = mise_en_relation(df,['PAR_PLACE_Q'],n)  \n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_REUSSITE_GAGNE_'] = mise_en_relation(df,['PAR_REUSSITE_GAGNE'],n)           \n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_REUSSITE_QUINTE_'] = mise_en_relation(df,['PAR_REUSSITE_QUINTE'],n)          \n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_RUESSITE_PLACE_'] = mise_en_relation(df,['PAR_RUESSITE_PLACE'],n)  \n",
    "        df.loc[df['IDCOURSE'] ==n, 'POIDS_'] = mise_en_relation(df,['POIDS'],n) \n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_ENT_ECART_PLACE_'] = mise_en_relation(df,['PAR_ENT_ECART_PLACE'],n) \n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_VICTOIRE_'] = mise_en_relation(df,['PAR_VICTOIRE'],n) \n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_VICTOIRE_Q_'] = mise_en_relation(df,['PAR_VICTOIRE_Q'],n) \n",
    "        df.loc[df['IDCOURSE'] ==n, 'PAR_ENT_NB_COURSE_'] = mise_en_relation(df,['PAR_ENT_NB_COURSE'],n) \n",
    "        \n",
    "        \n",
    "    df[['PAR_REUSSITE_3P']] = df[['PAR_REUSSITE_3P_']]\n",
    "    df[['PAR_CARRIERE']]= df[['PAR_CARRIERE_']]\n",
    "    df[['PAR_CARRIERE_Q']] = df[['PAR_CARRIERE_Q_']]\n",
    "    df[['PAR_CLASSE_AGE']] = df[['PAR_CLASSE_AGE_']]\n",
    "    df[['PAR_COTEDER']] = df[['PAR_COTEDER_']]\n",
    "    df[['PAR_ENT_ECART_GAGNANT']] = df[['PAR_ENT_ECART_GAGNANT_']]\n",
    "    df[['PAR_ENT_RAPPORT_GAGNANT_M']] = df[['PAR_ENT_RAPPORT_GAGNANT_M_']]\n",
    "    df[['PAR_ENT_REU_PLACE']] = df[['PAR_ENT_REU_PLACE_']]\n",
    "    df[['PAR_ENT_REUSSITE_GAGNE']] = df[['PAR_ENT_REUSSITE_GAGNE_']]\n",
    "    df[['PAR_ENT_VICTOIRE']]= df[['PAR_ENT_VICTOIRE_']]\n",
    "    df[['PAR_PLACE']]= df[['PAR_PLACE_']]\n",
    "    df[['PAR_PLACE_Q']]= df[['PAR_PLACE_Q_']]\n",
    "    df[['PAR_REUSSITE_GAGNE']]= df[['PAR_REUSSITE_GAGNE_']]\n",
    "    df[['PAR_REUSSITE_QUINTE']]= df[['PAR_REUSSITE_QUINTE_']]\n",
    "    df[['PAR_RUESSITE_PLACE']]= df[['PAR_RUESSITE_PLACE_']]\n",
    "    df[['POIDS']]= df[['POIDS_']]\n",
    "    df[['PAR_ENT_ECART_PLACE']]= df[['PAR_ENT_ECART_PLACE_']]\n",
    "    df[['PAR_VICTOIRE']]= df[['PAR_VICTOIRE_']]\n",
    "    df[['PAR_VICTOIRE_Q']]= df[['PAR_VICTOIRE_Q_']]\n",
    "    df[['PAR_ENT_NB_COURSE']]= df[['PAR_ENT_NB_COURSE_']]\n",
    "    \n",
    "    \n",
    "    print(timer(start_time))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_drop(df, col):\n",
    "    if col in df:\n",
    "        df.drop([col], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def encodage(df_x):\n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "    #le = preprocessing.LabelEncoder()\n",
    "    #df_gagnant[['HIPPO']] = le.fit_transform(df_gagnant[['HIPPO']])\n",
    "    #df_gagnant[['PAR_PROPRIO']] = le.fit_transform(df_gagnant[['PAR_PROPRIO']])\n",
    "    ##f_gagnant[['NOM_JOC']] = le.fit_transform(df_gagnant[['NOM_JOC']])\n",
    "    #df_gagnant[['NOM_ENTR']] = le.fit_transform(df_gagnant[['NOM_ENTR']])\n",
    "    #df_gagnant[['CHEVAL']] = le.fit_transform(df_gagnant[['CHEVAL']])\n",
    "    #df_gagnant[['PAR_NUM']] = le.fit_transform(df_gagnant[['PAR_NUM']])\n",
    "   # df_gagnant[['MUSIC_CHEVAL']] = le.fit_transform(df_gagnant[['MUSIC_CHEVAL']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #scaler = RobustScaler()\n",
    "   # scaler = RobustScaler( with_scaling=False, quantile_range=(30.0, 70.0), copy=False)\n",
    "\n",
    "    critere_scale = [\n",
    "      \n",
    "              \n",
    "              'PAR_AGE',\n",
    "              'PAR_CARRIERE',\n",
    "              'PAR_CARRIERE_Q',\n",
    "              'PAR_CLASSE_AGE',\n",
    "              'PAR_COTEDER',\n",
    "              'PAR_ENT_ECART_GAGNANT',\n",
    "              'PAR_ENT_RAPPORT_GAGNANT_M',\n",
    "              'PAR_ENT_REU_PLACE',\n",
    "              'PAR_ENT_REUSSITE_GAGNE',\n",
    "              'PAR_ENT_VICTOIRE',\n",
    "              'PAR_GAIN',\n",
    "              'pAR_JOC_ECART_GAGNANT',\n",
    "              'PAR_JOC_ECART_PLACE',\n",
    "              'PAR_JOC_NB_COURSE',\n",
    "              'PAR_JOC_PLACE_3P',\n",
    "              'pAR_JOC_RAPPORT_GAGNANT_M',\n",
    "              'PAR_JOC_REU_PLACE',\n",
    "              'pAR_JOC_REUSSITE_GAGNE',\n",
    "              'pAR_JOC_VICTOIRE',\n",
    "              'PAR_NP',\n",
    "              'PAR_NUM',\n",
    "              'PAR_PLACE',\n",
    "              'PAR_PLACE_Q',\n",
    "              'PAR_REUSSITE_3P',\n",
    "              'PAR_REUSSITE_GAGNE',\n",
    "              'PAR_REUSSITE_QUINTE',\n",
    "              'PAR_RUESSITE_PLACE',\n",
    "\n",
    "              \n",
    "\n",
    "          #    'Point',\n",
    "              \n",
    "\n",
    "              'POIDS',\n",
    "              \n",
    "              \n",
    "              'PAR_ENT_ECART_PLACE',\n",
    "              'PAR_VICTOIRE',\n",
    "              'PAR_VICTOIRE_Q',\n",
    "          'PAR_ENT_NB_COURSE',\n",
    "                      ]\n",
    "    \n",
    "    \n",
    "\n",
    "     \n",
    "\n",
    "    #df_gagnant[critere_scale] = quantile_transform(df_gagnant[critere_scale], n_quantiles=4)\n",
    "\n",
    "    #df_gagnant[critere_scale] = qt.fit_transform(df_gagnant[critere_scale])\n",
    "    df_x[critere_scale] = quantile_transform(df_x[critere_scale], n_quantiles=5000, random_state=0,subsample=300000)\n",
    "\n",
    "   # df_x[critere_scale] = scaler.fit_transform(df_x[critere_scale])\n",
    "\n",
    "    return df_x,critere_scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Lecture des données sans index\n",
    "xnames = ['ALLURE', 'CO_DISTANCE',\n",
    "              'CO_PRIX', 'HIPPO',\n",
    "              'IDCOURSE', 'IDPARTCIPANT',\n",
    "              'PAR_AGE', 'PAR_ARRIVE',\n",
    "              'PAR_CARRIERE',\n",
    "              'PAR_CARRIERE_Q',\n",
    "              'PAR_CLASSE_AGE',\n",
    "              'PAR_COTEDER',\n",
    "              'PAR_ENT_ECART_GAGNANT',\n",
    "              'PAR_ENT_RAPPORT_GAGNANT_M',\n",
    "              'PAR_ENT_REU_PLACE',\n",
    "              'PAR_ENT_REUSSITE_GAGNE',\n",
    "              'PAR_ENT_VICTOIRE',\n",
    "              'PAR_GAIN',\n",
    "              'pAR_JOC_ECART_GAGNANT',\n",
    "              'PAR_JOC_ECART_PLACE',\n",
    "              'PAR_JOC_NB_COURSE',\n",
    "              'PAR_JOC_PLACE_3P',\n",
    "              'pAR_JOC_RAPPORT_GAGNANT_M',\n",
    "              'PAR_JOC_REU_PLACE',\n",
    "              'pAR_JOC_REUSSITE_GAGNE',\n",
    "              'pAR_JOC_VICTOIRE',\n",
    "              'PAR_NP',\n",
    "              'PAR_NUM',\n",
    "              'PAR_PLACE',\n",
    "              'PAR_PLACE_Q',\n",
    "              'PAR_REUSSITE_3P',\n",
    "              'PAR_REUSSITE_GAGNE',\n",
    "              'PAR_REUSSITE_QUINTE',\n",
    "              'PAR_RUESSITE_PLACE',\n",
    "              'autostart',\n",
    "              'cendre',\n",
    "              'grande_piste',\n",
    "              'Point',\n",
    "              'Nb_partant',\n",
    "              'PAR_PROPRIO',\n",
    "              'NOM_JOC',\n",
    "              'NOM_ENTR',\n",
    "              'POIDS',\n",
    "              'CORDE', 'CHEVAL',\n",
    "              'MUSIC_CHEVAL',\n",
    "              'MUSIC_ENT',\n",
    "              'MUSIC_JOC',\n",
    "              'PAR_VALEUR',\n",
    "              'PAR_ENT_ECART_PLACE',\n",
    "              'PAR_VICTOIRE',\n",
    "              'PAR_VICTOIRE_Q',\n",
    "          'PAR_ENT_NB_COURSE',\n",
    "              'FIN_ligne']\n",
    "\n",
    "# Creating bins for the win column\n",
    "def assign_selection(W):\n",
    "    if W <=2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    # Creating bins for the win column\n",
    "def assign_selection2(W):\n",
    "    if W == 1.0:\n",
    "        return 1\n",
    "    if W == 0.0:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-24 22:47:18.000190\n",
      "DATA ....\n",
      "2018-06-24 22:47:18.001188\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 2.44 seconds.\n",
      "None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 2.44 seconds.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "index_col = ['IDCOURSE','IDPARTCIPANT']\n",
    "start_time=timer()\n",
    "df = lecture_data('d:\\data_diabolo.csv', xnames, xindex_col=index_col, allure=allure_etudier, avec_index=False)\n",
    "df.reindex(columns = ['IDCOURSE', 'IDPARTCIPANT']) \n",
    "print(timer(start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MAXX']=0\n",
    "df['CRI']=0\n",
    "df['POINT2018']=0\n",
    "\n",
    "def donne_note(val_cri, maxx):\n",
    "    if maxx==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (val_cri/maxx)*20\n",
    "    \n",
    "    \n",
    "def calcul_note(df, num_course, cri):\n",
    "\n",
    "    print(cri)\n",
    "    dd=df.loc[df['IDCOURSE']==num_course,cri]  # selection critere\n",
    "    #determine max de ce critere\n",
    "    maxx=dd.max() #MAXI\n",
    "    print(maxx)\n",
    "    df.loc[df['IDCOURSE']==num_course,'MAXX']=maxx[0] #selection Max sans colonne\n",
    "\n",
    "    #print( num_course, (df.loc[df['IDCOURSE']==num_course,  cri[0]] ))\n",
    "\n",
    "    df.loc[df['IDCOURSE']==num_course,'CRI'] =  ( df.loc[df['IDCOURSE']==num_course,  cri[0]]   / maxx[0])*20\n",
    "    df.loc[df['IDCOURSE']==num_course, cri[0]] =  df.loc[df['IDCOURSE']==num_course,'CRI'] \n",
    "        \n",
    "    \n",
    "  \n",
    "   #df.loc[df['IDCOURSE']==ncourse,'POINT2018'] = df.loc[df['IDCOURSE']==ncourse,'POINT2018'] + df.loc[df['IDCOURSE']==ncourse,'CRI']\n",
    "    return  df\n",
    "\n",
    "\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course  1616\n",
      "['PAR_REUSSITE_3P']\n",
      "PAR_REUSSITE_3P    0.533333\n",
      "dtype: float64\n",
      "\n",
      " 13    14.634159\n",
      "14     4.918053\n",
      "15    11.295195\n",
      "16    12.499995\n",
      "17    11.132819\n",
      "18    10.227269\n",
      "19    11.383920\n",
      "20    12.499995\n",
      "21    16.216210\n",
      "22    14.880947\n",
      "23     8.388155\n",
      "24    10.500007\n",
      "25    20.000000\n",
      "26     9.740256\n",
      "27     6.976767\n",
      "28    12.499995\n",
      "29    17.500023\n",
      "30     7.870392\n",
      "Name: POINT2018, dtype: float64\n",
      "Course  1617\n",
      "['PAR_REUSSITE_3P']\n",
      "PAR_REUSSITE_3P    0.545455\n",
      "dtype: float64\n",
      "\n",
      " 31    16.666673\n",
      "32    16.041653\n",
      "33    19.743590\n",
      "34     8.461523\n",
      "35    16.666673\n",
      "36     7.638870\n",
      "37    11.578957\n",
      "38    12.222200\n",
      "39    12.222200\n",
      "40    20.000000\n",
      "41     9.777782\n",
      "42     9.166659\n",
      "Name: POINT2018, dtype: float64\n",
      "Course  1618\n",
      "['PAR_REUSSITE_3P']\n",
      "PAR_REUSSITE_3P    0.571429\n",
      "dtype: float64\n",
      "\n",
      " 43    14.736844\n",
      "44    14.259234\n",
      "45    11.199992\n",
      "46    12.173901\n",
      "47    20.000000\n",
      "48    14.736844\n",
      "49    13.333310\n",
      "50     7.954549\n",
      "51    12.894725\n",
      "52     4.374997\n",
      "53    13.999990\n",
      "54    12.962940\n",
      "55    17.499987\n",
      "56     9.843743\n",
      "57     6.999995\n",
      "58    15.909098\n",
      "Name: POINT2018, dtype: float64\n",
      "Course  1619\n",
      "['PAR_REUSSITE_3P']\n",
      "PAR_REUSSITE_3P    1.0\n",
      "dtype: float64\n",
      "\n",
      " 59    20.00000\n",
      "60     8.00000\n",
      "61     3.33334\n",
      "62     5.71428\n",
      "63     7.50000\n",
      "64     4.44444\n",
      "65    12.00000\n",
      "66     4.00000\n",
      "67    15.00000\n",
      "68     3.07692\n",
      "69    13.33334\n",
      "70     5.71428\n",
      "71     6.66666\n",
      "Name: POINT2018, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for n  in df.groupby(['IDCOURSE'],axis=0):\n",
    "    nc=n[0]\n",
    "    print(\"Course \",nc)\n",
    "    df= calcul_note(df, nc, ['PAR_REUSSITE_3P'] )\n",
    "    #print(\"NOTE  **********df=\",df.loc[df['IDCOURSE']==ncourse,'PAR_REUSSITE_3P'])\n",
    "    \n",
    "    #Somme de point obtenu pour UN criter pour le course NC\n",
    "    df.loc[df['IDCOURSE']==nc,'POINT2018']    =   df.loc[df['IDCOURSE']==nc,'POINT2018'] + df.loc[df['IDCOURSE']==nc,'CRI']\n",
    "    print('\\n',df.loc[df['IDCOURSE']==nc,'POINT2018'] )\n",
    "          \n",
    "    i=i+1\n",
    "    if i==4:\n",
    "        break\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
