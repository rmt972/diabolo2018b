{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "allure_etudier=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating system version.... Windows-10-10.0.17134-SP0\n",
      "Python version is........... 3.6.5\n",
      "scikit-learn version is..... 0.19.1\n",
      "pandas version is........... 0.22.0\n",
      "numpy version is............ 1.14.2\n",
      "matplotlib version is....... 2.2.0\n",
      "scipy version is....... 1.0.0\n"
     ]
    }
   ],
   "source": [
    "import  sys\n",
    "\n",
    "#LOCALISATION DES DONNEES\n",
    "sys.path.insert(0, \"C:/projets_python/diabolo\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from math import *\n",
    "\n",
    "\n",
    "#LIBRAIRIES PERSO\n",
    "import etude_variable.MyLog as log\n",
    "import etude_variable.jouer as jouer\n",
    "\n",
    "import etude_variable.analyse as ana\n",
    "\n",
    "# LIBRAIRIE PYHTON CLASSIQUES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import scipy\n",
    "import platform\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "#ESTIMATEUR\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "\n",
    "#TRAINING\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "import dask_searchcv as dcv\n",
    "from skopt.space import Real, Integer\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#Evaluateur\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#outils\n",
    "from dask.diagnostics import ProgressBar\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#Metriques\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn import  metrics\n",
    "from sklearn.metrics import  roc_auc_score\n",
    "from sklearn.metrics import  classification_report\n",
    "\n",
    "#Outils\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "#Graphique\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print('Operating system version....', platform.platform())\n",
    "print(\"Python version is........... %s.%s.%s\" % sys.version_info[:3])\n",
    "print('scikit-learn version is.....', sklearn.__version__)\n",
    "print('pandas version is...........', pd.__version__)\n",
    "print('numpy version is............', np.__version__)\n",
    "print('matplotlib version is.......', matplotlib.__version__)\n",
    "print('scipy version is.......', scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins for the win column\n",
    "def assign_selection(W):\n",
    "    if W <=1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins for the win column\n",
    "def assign_selection_cote(W,C):\n",
    "    if W <=3 and C>4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lecture_data(Fichier, xnames, xindex_col, allure=1, mode_debug=0, avec_index=True):\n",
    "    if avec_index==True:\n",
    "        df = pd.read_csv(Fichier,  index_col=xindex_col,     sep=';',     names=xnames,               skipinitialspace=True,              encoding='Latin-1')\n",
    "    else:\n",
    "        df = pd.read_csv(Fichier,   index_col=None,  sep=';',                     names=xnames,                         skipinitialspace=True,     encoding='Latin-1')\n",
    "\n",
    "    df = df.groupby(\"ALLURE\")\n",
    "    df = df.get_group(allure)\n",
    "    #print(df.info())\n",
    "\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        print(start_time)\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "        \n",
    "\n",
    "        \n",
    "def split_dataset(dataset, train_percentage, feature_headers,\n",
    "                                  target_header,random_state=42,mode_debug=0):\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(dataset[feature_headers], dataset[target_header],\n",
    "                                                        train_size=train_percentage, test_size=None, random_state=42)\n",
    "\n",
    "\n",
    "    if mode_debug==1:\n",
    "        # Train and Test dataset size details\n",
    "        print(\"--------------------------------\")\n",
    "        print(\"Train_x Shape :: \", train_x.shape)\n",
    "        print(\"Train_y Shape :: \", train_y.shape)\n",
    "        print(\"Test_x Shape :: \", test_x.shape)\n",
    "        print(\"Test_y Shape :: \", test_y.shape)\n",
    "        print(\"--------------------------------\")\n",
    "\n",
    "    return train_x, test_x, train_y, test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_drop(df, col):\n",
    "    if col in df:\n",
    "        df.drop([col], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suppression_colonne(df2,allure):\n",
    "    # df=my_drop(df, \"PAR_AGE\")\n",
    "    print('Suppression colonnne ', allure)\n",
    "\n",
    "    if  allure==0:\n",
    "\n",
    "        df2.drop([\"FIN_ligne\"], axis=1, inplace=True)\n",
    "        df2.drop([\"PAR_NP\"], axis=1, inplace=True)\n",
    "        df2.drop([\"cendre\"], axis=1, inplace=True)\n",
    "        df2.drop([\"MUSIC_CHEVAL\"], axis=1, inplace=True)\n",
    "        df2.drop([\"MUSIC_ENT\"], axis=1, inplace=True)\n",
    "        df2.drop([\"MUSIC_JOC\"], axis=1, inplace=True)\n",
    "        df2.drop([\"grande_piste\"], axis=1, inplace=True)\n",
    "        df2.drop([\"PAR_VALEUR\"], axis=1, inplace=True)\n",
    "        df2.drop([\"autostart\"], axis=1, inplace=True)\n",
    "        #df2.drop([\"CO_DISTANCE\"], axis=1, inplace=True)\n",
    "        #df2.drop([\"Point\"], axis=1, inplace=True)\n",
    "        df2.drop([\"CHEVAL\"], axis=1, inplace=True)\n",
    "        df2.drop([\"HIPPO\"], axis=1, inplace=True)\n",
    "        df2.drop([\"NOM_JOC\"], axis=1, inplace=True)\n",
    "        df2.drop([\"NOM_ENTR\"], axis=1, inplace=True)\n",
    "        df2.drop([\"CO_PRIX\"], axis=1, inplace=True)\n",
    "        df2.drop([\"Point\"], axis=1, inplace=True)\n",
    "\n",
    "        df2.drop([\"PAR_PROPRIO\"], axis=1, inplace=True)\n",
    "        df2.drop([\"PAR_CARRIERE_Q\"], axis=1, inplace=True)\n",
    "        df2.drop([\"PAR_PLACE_Q\"], axis=1, inplace=True)\n",
    "        df2.drop([\"PAR_REUSSITE_QUINTE\"], axis=1, inplace=True)\n",
    "        df2.drop([\"PAR_VICTOIRE_Q\"], axis=1, inplace=True)\n",
    "        df2.drop([\"PAR_COTEDER\"], axis=1, inplace=True)\n",
    "\n",
    "        \n",
    "    \n",
    "        df2 = my_drop(df2, 'PAR_GAIN')     \n",
    "        df2 = my_drop(df2, 'PAR_CLASSE_AGE')     \n",
    "\n",
    "\n",
    "        \n",
    "    if allure == 1:\n",
    "        df2 = my_drop(df2, \"POIDS\")\n",
    "        df2 = my_drop(df2, \"CORDE\")\n",
    "   \n",
    "    if allure==2:\n",
    "        \n",
    "        df2 = my_drop(df2, \"MY_auto_start\")\n",
    "      #  df2 = my_drop(df2, \"PAR_VICTOIRE_Q\") \n",
    "\n",
    "    if allure == 3:\n",
    "        df2 = my_drop(df2, \"POIDS\")\n",
    "        df2 = my_drop(df2, \"CORDE\")\n",
    "        df2 = my_drop(df2, \"MY_auto_start\")\n",
    "\n",
    "\n",
    "    if allure == 4:\n",
    "        df2 = my_drop(df2, \"CORDE\")\n",
    "        df2 = my_drop(df2, \"MY_auto_start\")\n",
    "\n",
    "\n",
    "    if allure == 5:\n",
    "        df2 = my_drop(df2, \"CORDE\")\n",
    "        df2 = my_drop(df2, \"MY_auto_start\")\n",
    "\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Lecture des données sans index\n",
    "xnames = ['ALLURE', 'CO_DISTANCE',\n",
    "              'CO_PRIX', 'HIPPO',\n",
    "              'IDCOURSE', 'IDPARTCIPANT',\n",
    "              'PAR_AGE', 'PAR_ARRIVE',\n",
    "              'PAR_CARRIERE',\n",
    "              'PAR_CARRIERE_Q',\n",
    "              'PAR_CLASSE_AGE',\n",
    "              'PAR_COTEDER',\n",
    "              'PAR_ENT_ECART_GAGNANT',\n",
    "              'PAR_ENT_RAPPORT_GAGNANT_M',\n",
    "              'PAR_ENT_REU_PLACE',\n",
    "              'PAR_ENT_REUSSITE_GAGNE',\n",
    "              'PAR_ENT_VICTOIRE',\n",
    "              'PAR_GAIN',\n",
    "              'pAR_JOC_ECART_GAGNANT',\n",
    "              'PAR_JOC_ECART_PLACE',\n",
    "              'PAR_JOC_NB_COURSE',\n",
    "              'PAR_JOC_PLACE_3P',\n",
    "              'pAR_JOC_RAPPORT_GAGNANT_M',\n",
    "              'PAR_JOC_REU_PLACE',\n",
    "              'pAR_JOC_REUSSITE_GAGNE',\n",
    "              'pAR_JOC_VICTOIRE',\n",
    "              'PAR_NP',\n",
    "              'PAR_NUM',\n",
    "              'PAR_PLACE',\n",
    "              'PAR_PLACE_Q',\n",
    "              'PAR_REUSSITE_3P',\n",
    "              'PAR_REUSSITE_GAGNE',\n",
    "              'PAR_REUSSITE_QUINTE',\n",
    "              'PAR_RUESSITE_PLACE',\n",
    "              'autostart',\n",
    "              'cendre',\n",
    "              'grande_piste',\n",
    "              'Point',\n",
    "              'Nb_partant',\n",
    "              'PAR_PROPRIO',\n",
    "              'NOM_JOC',\n",
    "              'NOM_ENTR',\n",
    "              'POIDS',\n",
    "              'CORDE', 'CHEVAL',\n",
    "              'MUSIC_CHEVAL',\n",
    "              'MUSIC_ENT',\n",
    "              'MUSIC_JOC',\n",
    "              'PAR_VALEUR',\n",
    "              'PAR_ENT_ECART_PLACE',\n",
    "              'PAR_VICTOIRE',\n",
    "              'PAR_VICTOIRE_Q',\n",
    "          'PAR_ENT_NB_COURSE',\n",
    "              'FIN_ligne']\n",
    "\n",
    "\n",
    "xnames2 = [\n",
    "              'CO_PRIX', 'HIPPO',\n",
    "              'IDCOURSE', 'IDPARTCIPANT',\n",
    "              'PAR_AGE',\n",
    "              'PAR_CARRIERE',\n",
    "              'PAR_CARRIERE_Q',\n",
    "              'PAR_CLASSE_AGE',\n",
    "              'PAR_COTEDER',\n",
    "              'PAR_ENT_ECART_GAGNANT',\n",
    "              'PAR_ENT_RAPPORT_GAGNANT_M',\n",
    "              'PAR_ENT_REU_PLACE',\n",
    "              'PAR_ENT_REUSSITE_GAGNE',\n",
    "              'PAR_ENT_VICTOIRE',\n",
    "              'PAR_GAIN',\n",
    "              'pAR_JOC_ECART_GAGNANT',\n",
    "              'PAR_JOC_ECART_PLACE',\n",
    "              'PAR_JOC_NB_COURSE',\n",
    "              'PAR_JOC_PLACE_3P',\n",
    "              'pAR_JOC_RAPPORT_GAGNANT_M',\n",
    "              'PAR_JOC_REU_PLACE',\n",
    "              'pAR_JOC_REUSSITE_GAGNE',\n",
    "              'pAR_JOC_VICTOIRE',\n",
    "              'PAR_NP',\n",
    "              'PAR_NUM',\n",
    "              'PAR_PLACE',\n",
    "              'PAR_PLACE_Q',\n",
    "              'PAR_REUSSITE_3P',\n",
    "              'PAR_REUSSITE_GAGNE',\n",
    "              'PAR_REUSSITE_QUINTE',\n",
    "              'PAR_RUESSITE_PLACE',\n",
    "              'autostart',\n",
    "              'cendre',\n",
    "              'grande_piste',\n",
    "              'Point',\n",
    "              'Nb_partant',\n",
    "              'PAR_PROPRIO',\n",
    "              'NOM_JOC',\n",
    "              'NOM_ENTR',\n",
    "              'POIDS',\n",
    "              'CORDE', 'CHEVAL',\n",
    "              'MUSIC_CHEVAL',\n",
    "              'MUSIC_ENT',\n",
    "              'MUSIC_JOC',\n",
    "              'PAR_VALEUR',\n",
    "              'PAR_ENT_ECART_PLACE',\n",
    "              'PAR_VICTOIRE',\n",
    "              'PAR_VICTOIRE_Q',\n",
    "              'PAR_ENT_NB_COURSE',\n",
    "              'FIN_ligne',\n",
    "               'SELECTION2',\n",
    "               'p2018']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation(df2,allure_etudier):\n",
    "    #Filtre des données¶\n",
    "    print('\\n\\n----------- TRANSFORMATION --------- AJOUT DE COLONNE------------\\n')\n",
    "    start_time=timer()\n",
    "    #df2=df2[df2.Point>0]\n",
    "    df2 = df2[df2.PAR_COTEDER > 0]\n",
    "   # df2 = df2[df2.CO_PRIX > 0]\n",
    "    df2 = df2[df2.PAR_GAIN >= 0]\n",
    "    df2 = df2[df2.Nb_partant >= 7]\n",
    "          #  df2.drop([\"Nb_partant\"], axis=1, inplace=True)\n",
    "    df2 = df2[df2.PAR_GAIN < 1000000]\n",
    "    df2 = df2[df2.PAR_ARRIVE > 0]  # On garde la ligne qui possede information arrivée\n",
    "    \n",
    "    df2 = df2.groupby(\"ALLURE\")\n",
    "    df2 = df2.get_group(allure_etudier)\n",
    "    df2 = my_drop(df2, 'ALLURE')\n",
    "    \n",
    "    if allure_etudier == 2 or allure_etudier == 4 or allure_etudier == 5:\n",
    "        df2 = df2[df2.POIDS > 20]\n",
    "        df2 = df2[df2.POIDS < 80]\n",
    "        \n",
    "    #  on a lu les données avant l 'ajout de la colonne SELECTIOB\n",
    "    df2['SELECTION2'] = df2['PAR_ARRIVE'].apply(assign_selection)\n",
    "    #df2['SELECTION2'] = df2.apply(lambda x: assign_selection_cote(x['PAR_ARRIVE'], x['PAR_COTEDER']), axis=1)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df2 = my_drop(df2, 'PAR_ARRIVE')\n",
    "\n",
    "    #df2['CHEVAL_QUINTE'] = df2.apply(lambda x: CHEVAL_QUINTE(x['PAR_CARRIERE_Q']), axis=1)    \n",
    "    timer(start_time)\n",
    "    return df2\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def somme_note(df,num_course,cri):\n",
    "   \n",
    "    df.loc[df['IDCOURSE']==num_course,'p2018']  = df.loc[df['IDCOURSE']==num_course,'p2018'] +   df.loc[df['IDCOURSE']==num_course, cri]\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "        \n",
    "     \n",
    "            \n",
    "def calcul_note(df, num_course, cri):\n",
    "    df.loc[df['IDCOURSE']==num_course,'aux'] = df.loc[df['IDCOURSE']==num_course,cri[0]]                                                \n",
    "    valeur_critere=df.loc[df['IDCOURSE']==num_course,cri]  # selection critere     \n",
    "    maxx=valeur_critere.max() #MAXI    \n",
    "    \n",
    "    if ((maxx[0])>0):\n",
    "        df.loc[df['IDCOURSE']==num_course,cri ]= ( df.loc[df['IDCOURSE']==num_course,cri]  /maxx[0]) *20  \n",
    "    else:\n",
    "        df.loc[df['IDCOURSE']==num_course,cri]=0\n",
    "                        \n",
    "    df=somme_note(df,num_course, cri[0])\n",
    "    df.loc[df['IDCOURSE']==num_course,cri[0]] =    df.loc[df['IDCOURSE']==num_course,'aux']            \n",
    "    \n",
    "    return  df\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def calcul_les_notes(df):\n",
    "    i=0\n",
    "    start_time=timer()\n",
    "    df['p2018']=0\n",
    "    df['aux']=0\n",
    "\n",
    "        \n",
    "    \n",
    "    for n  in df.groupby(['IDCOURSE'],axis=0):\n",
    "        nc=n[0]\n",
    "        if math.fmod(i,500)==0 or i<20:\n",
    "            print(\"    print(N° \",i,timer(start_time))\n",
    "            #df= calcul_note(df, nc, ['PAR_CARRIERE'] )\n",
    "        df= calcul_note(df, nc, ['PAR_ENT_ECART_GAGNANT'] )\n",
    "        df= calcul_note(df, nc, ['PAR_ENT_RAPPORT_GAGNANT_M'] )\n",
    "        df= calcul_note(df, nc, ['PAR_ENT_REU_PLACE'] )\n",
    "        df= calcul_note(df, nc, ['PAR_ENT_REUSSITE_GAGNE'] )\n",
    "        df= calcul_note(df, nc, ['PAR_ENT_VICTOIRE'] ) \n",
    "        df= calcul_note(df, nc, ['PAR_ENT_NB_COURSE'] )   \n",
    "    \n",
    "        df= calcul_note(df, nc, ['pAR_JOC_ECART_GAGNANT'] )\n",
    "        df= calcul_note(df, nc, ['pAR_JOC_RAPPORT_GAGNANT_M'] )\n",
    "        df= calcul_note(df, nc, ['PAR_JOC_REU_PLACE'] )\n",
    "        \n",
    "        df= calcul_note(df, nc, ['pAR_JOC_REUSSITE_GAGNE'] )\n",
    "        df= calcul_note(df, nc, ['pAR_JOC_VICTOIRE'] )    \n",
    "        df= calcul_note(df, nc, ['PAR_JOC_ECART_PLACE'] )\n",
    "        df= calcul_note(df, nc, ['PAR_JOC_NB_COURSE'] )    \n",
    "        df= calcul_note(df, nc, ['PAR_JOC_PLACE_3P'] )    \n",
    "    \n",
    "        df= calcul_note(df, nc, ['PAR_REUSSITE_GAGNE'] )\n",
    "        df= calcul_note(df, nc, ['PAR_RUESSITE_PLACE'] )\n",
    "        df= calcul_note(df, nc, ['PAR_REUSSITE_3P'] )    \n",
    "        df= calcul_note(df, nc, ['PAR_CARRIERE'] )\n",
    "        df= calcul_note(df, nc, ['PAR_CARRIERE_Q'] )\n",
    "        df= calcul_note(df, nc, ['PAR_GAIN'] )\n",
    "        df= calcul_note(df, nc, ['PAR_PLACE'] )\n",
    "        df= calcul_note(df, nc, ['PAR_PLACE_Q'] )\n",
    "        df= calcul_note(df, nc, ['PAR_CLASSE_AGE'] )\n",
    "        df= calcul_note(df, nc, ['PAR_VICTOIRE'] )\n",
    "        df= calcul_note(df, nc, ['PAR_REUSSITE_QUINTE'] )\n",
    "        df= calcul_note(df, nc, ['PAR_VICTOIRE_Q'] )\n",
    "        df= calcul_note(df, nc, ['PAR_ENT_ECART_PLACE'] )\n",
    "      \n",
    "        i=i+1\n",
    "   \n",
    "            \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyer_Nan(df):\n",
    "    df[['PAR_ENT_ECART_GAGNANT']] = df[['PAR_ENT_ECART_GAGNANT']].fillna( df[['PAR_ENT_ECART_GAGNANT']].mean())\n",
    "    df[['PAR_ENT_RAPPORT_GAGNANT_M']] = df[['PAR_ENT_RAPPORT_GAGNANT_M']].fillna( df[['PAR_ENT_RAPPORT_GAGNANT_M']].mean())\n",
    "    df[['PAR_ENT_REU_PLACE']] = df[['PAR_ENT_REU_PLACE']].fillna( df[['PAR_ENT_REU_PLACE']].mean())\n",
    "    df[['PAR_ENT_REUSSITE_GAGNE']] = df[['PAR_ENT_REUSSITE_GAGNE']].fillna( df[['PAR_ENT_REUSSITE_GAGNE']].mean())\n",
    "    df[['PAR_ENT_VICTOIRE']] = df[['PAR_ENT_VICTOIRE']].fillna( df[['PAR_ENT_VICTOIRE']].mean())\n",
    "    df[['PAR_ENT_NB_COURSE']] = df[['PAR_ENT_NB_COURSE']].fillna( df[['PAR_ENT_NB_COURSE']].mean())\n",
    "    \n",
    "    df[['pAR_JOC_ECART_GAGNANT']] = df[['pAR_JOC_ECART_GAGNANT']].fillna( df[['pAR_JOC_ECART_GAGNANT']].mean())\n",
    "    df[['pAR_JOC_RAPPORT_GAGNANT_M']] = df[['pAR_JOC_RAPPORT_GAGNANT_M']].fillna( df[['pAR_JOC_RAPPORT_GAGNANT_M']].mean())\n",
    "    df[['PAR_JOC_REU_PLACE']] = df[['PAR_JOC_REU_PLACE']].fillna( df[['PAR_JOC_REU_PLACE']].mean())\n",
    "    df[['pAR_JOC_REUSSITE_GAGNE']] = df[['pAR_JOC_REUSSITE_GAGNE']].fillna( df[['pAR_JOC_REUSSITE_GAGNE']].mean())\n",
    "    df[['pAR_JOC_VICTOIRE']] = df[['pAR_JOC_VICTOIRE']].fillna( df[['pAR_JOC_VICTOIRE']].mean())\n",
    "    df[['PAR_JOC_ECART_PLACE']] = df[['PAR_JOC_ECART_PLACE']].fillna( df[['PAR_JOC_ECART_PLACE']].mean())\n",
    "    df[['PAR_JOC_NB_COURSE']] = df[['PAR_JOC_NB_COURSE']].fillna( df[['PAR_JOC_NB_COURSE']].mean())\n",
    "    df[['PAR_JOC_PLACE_3P']] = df[['PAR_JOC_PLACE_3P']].fillna( df[['PAR_JOC_PLACE_3P']].mean())\n",
    "    df['PAR_RUESSITE_PLACE'] = df['PAR_RUESSITE_PLACE'].fillna( df['PAR_RUESSITE_PLACE'].mean())\n",
    "    df[['PAR_REUSSITE_GAGNE']] = df[['PAR_REUSSITE_GAGNE']].fillna( 0)\n",
    "    df[['PAR_REUSSITE_3P']] = df[['PAR_REUSSITE_3P']].fillna( df[['PAR_REUSSITE_3P']].mean())\n",
    "    df[['PAR_CARRIERE']] = df[['PAR_CARRIERE']].fillna( df[['PAR_CARRIERE']].mean())\n",
    "    df[['PAR_CARRIERE_Q']] = df[['PAR_CARRIERE_Q']].fillna( df[['PAR_CARRIERE_Q']].mean())\n",
    "    df[['PAR_GAIN']] = df[['PAR_GAIN']].fillna( df[['PAR_GAIN']].mean())    \n",
    "    df[['PAR_PLACE']] = df[['PAR_PLACE']].fillna( df[['PAR_PLACE']].mean())\n",
    "    df[['PAR_PLACE_Q']] = df[['PAR_PLACE_Q']].fillna( df[['PAR_PLACE_Q']].mean())\n",
    "    df[['PAR_CLASSE_AGE']] = df[['PAR_CLASSE_AGE']].fillna( df[['PAR_CLASSE_AGE']].mean())\n",
    "    df[['PAR_POINT']] = df[['PAR_POINT']].fillna( df[['PAR_POINT']].mean())\n",
    "    df[['PAR_REUSSITE_QUINTE']] = df[['PAR_REUSSITE_QUINTE']].fillna( df[['PAR_REUSSITE_QUINTE']].mean())\n",
    "    df[['PAR_VICTOIRE_Q']] = df[['PAR_VICTOIRE_Q']].fillna( df[['PAR_VICTOIRE_Q']].mean())\n",
    "    df[['PAR_ENT_ECART_PLACE']] = df[['PAR_ENT_ECART_PLACE']].fillna( df[['PAR_ENT_ECART_PLACE']].mean())\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "import math\n",
    "def relation_1(a,b):\n",
    "    if b==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (a/b)*20\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-10 22:28:33.967763\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 3.18 seconds.\n"
     ]
    }
   ],
   "source": [
    "index_col = ['IDPARTCIPANT', 'IDCOURSE']\n",
    "start_time=timer()\n",
    "df = lecture_data('d:\\data_diabolo.csv', xnames, xindex_col=index_col, allure=allure_etudier, avec_index=False)\n",
    "df = df.groupby(\"ALLURE\")\n",
    "df = df.get_group(allure_etudier)\n",
    "timer(start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nb_partant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Nb_partant\n",
       "100          14\n",
       "101          14\n",
       "102          14\n",
       "103          14\n",
       "104          14\n",
       "105          14\n",
       "106          14\n",
       "107          14\n",
       "108          14\n",
       "109          14"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Nb_partant']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------- TRANSFORMATION --------- AJOUT DE COLONNE------------\n",
      "\n",
      "2018-07-10 22:28:38.546104\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 0.44 seconds.\n"
     ]
    }
   ],
   "source": [
    "df2=transformation(df,allure_etudier)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-10 22:28:40.835960\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 0.09 seconds.\n",
      "    print(N°  0 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 1.27 seconds.\n",
      "    print(N°  1 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 1.78 seconds.\n",
      "    print(N°  2 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 2.28 seconds.\n",
      "    print(N°  3 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 2.76 seconds.\n",
      "    print(N°  4 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 3.31 seconds.\n",
      "    print(N°  5 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 3.85 seconds.\n",
      "    print(N°  6 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 4.33 seconds.\n",
      "    print(N°  7 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 4.84 seconds.\n",
      "    print(N°  8 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 5.4 seconds.\n",
      "    print(N°  9 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 5.91 seconds.\n",
      "    print(N°  10 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 6.4 seconds.\n",
      "    print(N°  11 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 6.9 seconds.\n",
      "    print(N°  12 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 7.38 seconds.\n",
      "    print(N°  13 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 7.91 seconds.\n",
      "    print(N°  14 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 8.47 seconds.\n",
      "    print(N°  15 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 8.96 seconds.\n",
      "    print(N°  16 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 9.47 seconds.\n",
      "    print(N°  17 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 10.02 seconds.\n",
      "    print(N°  18 None\n",
      "\n",
      " Time taken: 0 hours 0 minutes and 10.52 seconds.\n",
      "    print(N°  19 None\n"
     ]
    }
   ],
   "source": [
    "df2=calcul_les_notes(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF3 =df2.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2\n",
    "df2=DF3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "\n",
    "if allure_etudier==1:\n",
    "    df2.to_csv('d:\\diabolo_1_note.csv',sep=';',columns =xnames2, header=False)\n",
    "if allure_etudier==2:\n",
    "    Df2.to_csv('d:\\diabolo_2_note.csv',sep=';',columns =xnames2, header=False)    \n",
    "if allure_etudier==3:\n",
    "    df2.to_csv('d:\\diabolo_3_note.csv',sep=';',columns =xnames2, header=False)    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xnames2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if allure_etudier==1:\n",
    "    df2=pd.read_csv('d:\\diabolo_1_note.csv',   sep=';',  names=xnames2,                         skipinitialspace=True,     encoding='utf-8')\n",
    "    df2=df2.drop(df2.index[0])\n",
    "    df2.head(10)\n",
    "    \n",
    "if allure_etudier==2:\n",
    "    df2=pd.read_csv('d:\\diabolo_2_note.csv',   sep=';',  names=xnames2,                         skipinitialspace=True,     encoding='utf-8')\n",
    "    df2=df2.drop(df2.index[0])\n",
    "    df2.head(10)\n",
    "    \n",
    "if allure_etudier==3:\n",
    "    df2=pd.read_csv('d:\\diabolo_3_note.csv',   sep=';',  names=xnames2,                         skipinitialspace=True,     encoding='utf-8')\n",
    "    df2=df2.drop(df2.index[0])\n",
    "    df2.head(10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion(df2):\n",
    "    df2['CO_PRIX']=df2['CO_PRIX'].astype('int')\n",
    "    df2['HIPPO']=df2['HIPPO'].astype('int')\n",
    "    \n",
    "    df2['IDCOURSE']=df2['IDCOURSE'].astype('int')\n",
    "    df2['IDPARTCIPANT']=df2['IDPARTCIPANT'].astype('int')\n",
    "    df2['PAR_AGE']=df2['PAR_AGE'].astype('int')\n",
    "    df2['PAR_CARRIERE']=df2['PAR_CARRIERE'].astype('float')\n",
    "    df2['PAR_CARRIERE']=df2['PAR_CARRIERE'].astype('int')\n",
    "    df2['PAR_CARRIERE_Q']=df2['PAR_CARRIERE_Q'].astype('float')\n",
    "    df2['PAR_CARRIERE_Q']=df2['PAR_CARRIERE_Q'].astype('int')\n",
    "    df2['PAR_CLASSE_AGE']=df2['PAR_CLASSE_AGE'].astype('float')\n",
    "    df2['PAR_CLASSE_AGE']=df2['PAR_CLASSE_AGE'].astype('int')\n",
    "    df2['PAR_COTEDER']=df2['PAR_COTEDER'].astype('float')\n",
    "    df2['PAR_ENT_ECART_GAGNANT']=df2['PAR_ENT_ECART_GAGNANT'].astype('float')\n",
    "    df2['PAR_ENT_ECART_GAGNANT']=df2['PAR_ENT_ECART_GAGNANT'].astype('int')\n",
    "    df2['PAR_ENT_RAPPORT_GAGNANT_M']=df2['PAR_ENT_RAPPORT_GAGNANT_M'].astype('float')\n",
    "    df2['PAR_ENT_RAPPORT_GAGNANT_M']=df2['PAR_ENT_RAPPORT_GAGNANT_M'].astype('int')\n",
    "    df2['PAR_ENT_REU_PLACE']=df2['PAR_ENT_REU_PLACE'].astype('float')\n",
    "    df2['PAR_ENT_REUSSITE_GAGNE']=df2['PAR_ENT_REUSSITE_GAGNE'].astype('float')\n",
    "    df2['PAR_ENT_VICTOIRE']=df2['PAR_ENT_VICTOIRE'].astype('float')\n",
    "    df2['PAR_ENT_VICTOIRE']=df2['PAR_ENT_VICTOIRE'].astype('int')\n",
    "    df2['PAR_GAIN']=df2['PAR_GAIN'].astype('float')\n",
    "    df2['PAR_GAIN']=df2['PAR_GAIN'].astype('int')\n",
    "    df2['pAR_JOC_ECART_GAGNANT']=df2['pAR_JOC_ECART_GAGNANT'].astype('float')\n",
    "    df2['pAR_JOC_ECART_GAGNANT']=df2['pAR_JOC_ECART_GAGNANT'].astype('int')\n",
    "    df2['PAR_JOC_ECART_PLACE']=df2['PAR_JOC_ECART_PLACE'].astype('float')\n",
    "    df2['PAR_JOC_ECART_PLACE']=df2['PAR_JOC_ECART_PLACE'].astype('int')\n",
    "    df2['PAR_JOC_NB_COURSE']=df2['PAR_JOC_NB_COURSE'].astype('float')\n",
    "    df2['PAR_JOC_NB_COURSE']=df2['PAR_JOC_NB_COURSE'].astype('int')\n",
    "    df2['PAR_JOC_PLACE_3P']=df2['PAR_JOC_PLACE_3P'].astype('float')\n",
    "    df2['PAR_JOC_PLACE_3P']=df2['PAR_JOC_PLACE_3P'].astype('int')\n",
    "    df2['pAR_JOC_RAPPORT_GAGNANT_M']=df2['pAR_JOC_RAPPORT_GAGNANT_M'].astype('float')\n",
    "    df2['pAR_JOC_RAPPORT_GAGNANT_M']=df2['pAR_JOC_RAPPORT_GAGNANT_M'].astype('int')\n",
    "    df2['PAR_JOC_REU_PLACE']=df2['PAR_JOC_REU_PLACE'].astype('float')\n",
    "    df2['pAR_JOC_REUSSITE_GAGNE']=df2['pAR_JOC_REUSSITE_GAGNE'].astype('float')\n",
    "    df2['pAR_JOC_VICTOIRE']=df2['pAR_JOC_VICTOIRE'].astype('float')\n",
    "    df2['pAR_JOC_VICTOIRE']=df2['pAR_JOC_VICTOIRE'].astype('int')\n",
    "    df2['PAR_NP']=df2['PAR_NP'].astype('float')\n",
    "    df2['PAR_NP']=df2['PAR_NP'].astype('int')\n",
    "    df2['PAR_NUM']=df2['PAR_NUM'].astype('float')\n",
    "    df2['PAR_NUM']=df2['PAR_NUM'].astype('int')\n",
    "    df2['PAR_PLACE']=df2['PAR_PLACE'].astype('float')\n",
    "    df2['PAR_PLACE']=df2['PAR_PLACE'].astype('int')\n",
    "    df2['PAR_PLACE_Q']=df2['PAR_PLACE_Q'].astype('float')\n",
    "    df2['PAR_PLACE_Q']=df2['PAR_PLACE_Q'].astype('int')\n",
    "    df2['PAR_REUSSITE_3P']=df2['PAR_REUSSITE_3P'].astype('float')\n",
    "    df2['PAR_REUSSITE_GAGNE']=df2['PAR_REUSSITE_GAGNE'].astype('float')\n",
    "    df2['PAR_REUSSITE_QUINTE']=df2['PAR_REUSSITE_QUINTE'].astype('float')\n",
    "    df2['PAR_RUESSITE_PLACE']=df2['PAR_RUESSITE_PLACE'].astype('float')\n",
    "    df2['autostart']=df2['autostart'].astype('float')\n",
    "    df2['autostart']=df2['autostart'].astype('int')\n",
    "    df2['cendre']=df2['cendre'].astype('float')\n",
    "    df2['cendre']=df2['cendre'].astype('int')\n",
    "    df2['grande_piste']=df2['grande_piste'].astype('float')\n",
    "    df2['grande_piste']=df2['grande_piste'].astype('int')\n",
    "    df2['Point']=df2['Point'].astype('float')\n",
    "    df2['Point']=df2['Point'].astype('int')\n",
    "    df2['Nb_partant']=df2['Nb_partant'].astype('float')\n",
    "    df2['Nb_partant']=df2['Nb_partant'].astype('int')\n",
    "    df2['PAR_PROPRIO']=df2['PAR_PROPRIO'].astype('float')\n",
    "    df2['PAR_PROPRIO']=df2['PAR_PROPRIO'].astype('int')\n",
    "    df2['NOM_JOC']=df2['NOM_JOC'].astype('float')\n",
    "    df2['NOM_JOC']=df2['NOM_JOC'].astype('int')\n",
    "    df2['NOM_ENTR']=df2['NOM_ENTR'].astype('float')\n",
    "    df2['NOM_ENTR']=df2['NOM_ENTR'].astype('int')\n",
    "    df2['POIDS']=df2['POIDS'].astype('float')\n",
    "    df2['POIDS']=df2['POIDS'].astype('int')\n",
    "    df2['CORDE']=df2['CORDE'].astype('float')\n",
    "    df2['CORDE']=df2['CORDE'].astype('int')\n",
    "    df2['CHEVAL']=df2['CHEVAL'].astype('float')\n",
    "    df2['CHEVAL']=df2['CHEVAL'].astype('int')\n",
    "    df2['MUSIC_CHEVAL']=df2['MUSIC_CHEVAL'].astype('str')\n",
    "    df2['MUSIC_ENT']=df2['MUSIC_ENT'].astype('str')\n",
    "    df2['MUSIC_JOC']=df2['MUSIC_JOC'].astype('str')\n",
    "    df2['PAR_VALEUR']=df2['PAR_VALEUR'].astype('float')\n",
    "    df2['PAR_VALEUR']=df2['PAR_VALEUR'].astype('int')\n",
    "    df2['PAR_ENT_ECART_PLACE']=df2['PAR_ENT_ECART_PLACE'].astype('float')\n",
    "    df2['PAR_ENT_ECART_PLACE']=df2['PAR_ENT_ECART_PLACE'].astype('int')\n",
    "    df2['PAR_VICTOIRE']=df2['PAR_VICTOIRE'].astype('float')\n",
    "    df2['PAR_VICTOIRE']=df2['PAR_VICTOIRE'].astype('int')\n",
    "    df2['PAR_VICTOIRE_Q']=df2['PAR_VICTOIRE_Q'].astype('float')\n",
    "    df2['PAR_VICTOIRE_Q']=df2['PAR_VICTOIRE_Q'].astype('int')\n",
    "    df2['PAR_ENT_NB_COURSE']=df2['PAR_ENT_NB_COURSE'].astype('float')\n",
    "    df2['PAR_ENT_NB_COURSE']=df2['PAR_ENT_NB_COURSE'].astype('int')\n",
    "    df2['FIN_ligne']=df2['FIN_ligne'].astype('str')\n",
    "\n",
    "    df2['p2018']=df2['p2018'].astype('float')\n",
    "    df2['p2018']=df2['p2018'].astype('int')\n",
    "    df2['PAR_REUSSITE_QUINTE']=df2['PAR_REUSSITE_QUINTE'].astype('float')\n",
    "    df2['PAR_VICTOIRE_Q']=df2['PAR_VICTOIRE_Q'].astype('float')\n",
    "    df2['PAR_VICTOIRE_Q']=df2['PAR_VICTOIRE_Q'].astype('int')\n",
    "    \n",
    "    return df2\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=conversion(df2)\n",
    "df2['SELECTION2']=df2['SELECTION2'].astype('float')\n",
    "df2['SELECTION2']=df2['SELECTION2'].astype('int')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[['IDPARTCIPANT','PAR_REUSSITE_3P']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2=transformationPoint(df2,allure_etudier)\n",
    "#df2, critere_scale = encodage(df2)\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = suppression_colonne(df2=df2,allure=0)\n",
    "df2 = suppression_colonne(df2=df2,allure=allure_etudier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['IDPARTCIPANT','PAR_REUSSITE_3P']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2[['pAR_JOC_REUSSITE_GAGNE']].describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition de la cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins for the win column\n",
    "def assign_selection2(W):\n",
    "    if W==1:\n",
    "        return 1\n",
    "    if W==0:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "\n",
    "Lib_features_df = df2.columns\n",
    "xdata = df2.values\n",
    "\n",
    "df_gagnant = pd.DataFrame(data=xdata, columns=Lib_features_df)\n",
    "df_gagnant['SELECTION'] = df_gagnant['SELECTION2'].apply(assign_selection2)\n",
    "df_gagnant.drop([\"SELECTION2\"], axis=1, inplace=True)\n",
    "\n",
    "df_gagnant = df_gagnant.set_index(index_col)\n",
    "\n",
    "df_gagnant_len = len(df_gagnant.columns) - 1\n",
    "Lib_features = df_gagnant.columns[:df_gagnant_len]\n",
    "\n",
    "feature_columns = Lib_features  ##<<<<<<<<<<<<<<<<\n",
    "response_column = ['SELECTION']  ##<<<<<<<<<<<<<<<<\n",
    "log.traceLogdebug(\"Features                   : %s \" % Lib_features, \" <<<<************\")\n",
    "\n",
    "print(\"(1) Shape df_gagnant  \", df_gagnant.shape,\"\\n\")\n",
    "print(\"(2) FEATURES \",Lib_features)\n",
    "print(\"(3) response column \",response_column)\n",
    "# df_gagnant, feature_columns, response_column, ratio SONT DEFINI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suppression de colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_gagnant_len = len(df_gagnant.columns) - 1\n",
    "#Lib_features = df_gagnant.columns[:df_gagnant_len]\n",
    "feature_columns = Lib_features  ##<<<<<<<<<<<<<<<<\n",
    "#response_column = ['SELECTION']  ##<<<<<<<<<<<<<<<<\n",
    "log.traceLogdebug(\"Features                   : %s \" % Lib_features, \" <<<<************\")\n",
    "\n",
    "print(\"(1) Shape df_gagnant  \", df_gagnant.shape,\"\\n\")\n",
    "print(\"(2) FEATURES\\n \",Lib_features,\"\\n\")\n",
    "print(\"(3) response column \",response_column,\"\\n\")\n",
    "df_gagnant.info()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRELATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enfin, quelque chose de vraiment cool que vous pouvez mettre \n",
    "\n",
    "#dans une carte de chaleur est une matrice de corrélation. \n",
    "#Pandas DataFrame a une méthode corr qui calcule le coefficient de corrélation de Pearson (peut être un autre)\n",
    "#entre tous les couples de colonnes numériques du DataFrame.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(22,22))\n",
    "#sns.set(font_scale=6)\n",
    "sns.heatmap(df_gagnant.corr(), annot=True, fmt=\".2f\", linewidths=.0, ax=ax, annot_kws={\"size\": 12}, xticklabels = 1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count = df_gagnant['SELECTION'].value_counts()\n",
    "\n",
    "\n",
    "print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')\n",
    "target_count.plot(kind='bar', title='Count (target)')\n",
    "\n",
    "normal_trans_perc = sum(df_gagnant['SELECTION'] == 0) / (sum(df_gagnant['SELECTION'] == 0) + sum(df_gagnant['SELECTION'] == 1))\n",
    "fraud_trans_perc = 1 - normal_trans_perc\n",
    "print('Total number of records : {} '.format(len(df_gagnant)))\n",
    "print('Nombre de participations avec SELECTION = 0 : {}'.format(sum(df_gagnant['SELECTION'] == 0)))\n",
    "print('Nombre de participations avec SELECTION = 1  : {}'.format(sum(df_gagnant['SELECTION'] == 1)))\n",
    "print('Pourcentage 0: {:.4f}%,  pourcentage 1 : {:.4f}%'.format(normal_trans_perc * 100,fraud_trans_perc * 100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition des set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courbe_de_roc(model, test_x,test_y):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "    probas = model.predict_proba(test_x)\n",
    "    # probas est une matrice de deux colonnes avec la proabilités d'appartenance à chaque classe\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(test_y, probas[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print (\"Area under the ROC curve : %f\" % roc_auc)\n",
    "        \n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")   \n",
    "    \n",
    "def plot_importance(feature_columns, model):\n",
    "    importances = pd.DataFrame({'feature': feature_columns, 'importance': np.round(model.feature_importances_, 3)})\n",
    "    importances = importances.sort_values('importance', ascending=False).set_index('feature')\n",
    "    print(\"\")\n",
    "    print( importances)\n",
    "    importances.plot.bar()\n",
    "    \n",
    "    \n",
    "def metrique_classe(y_pred,y_true,xclass):\n",
    "    from imblearn.metrics import specificity_score\n",
    "    from imblearn.metrics import sensitivity_score\n",
    "\n",
    "\n",
    "    from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "\n",
    "\n",
    "    # La sensibilité est le rapport où est le nombre de vrais positifs et le nombre de faux négatifs.\n",
    "    # La sensibilité quantifie la capacité à éviter les faux négatifs.tp\n",
    "\n",
    "\n",
    "    # estimator issu de quelques FIT\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    log.traceLogInfo(\"Sensibilité  du re-equilibrage des données sur le TEST\")\n",
    "    #log.traceLogInfo(\"Binary \",sensitivity_score(y_true, y_pred, average='binary', pos_label=xclass))\n",
    "\n",
    "    log.traceLogInfo(\"La spécificité est intuitivement la capacité du classificateur à trouver tous les échantillons positifs\")\n",
    "\n",
    "    log.traceLogInfo(\"Binary \")\n",
    "    log.traceLogInfo(specificity_score(y_true, y_pred, labels=None, pos_label=xclass, average='binary', sample_weight=None))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nCalculer la moyenne géométrique\")\n",
    "    print(geometric_mean_score(y_true, y_pred,labels=None, pos_label=xclass))\n",
    "\n",
    "    print(\"\\n Calculer  sensitivity score\")\n",
    "    print(\"La sensibilité est le rapport où est le nombre de vrais positifs et le nombre de faux négatifs.\")\n",
    "    print(\"La sensibilité quantifie la capacité à éviter les faux négatifs.\")\n",
    "\n",
    "    print(sensitivity_score(y_true, y_pred, labels=None, pos_label=xclass,average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_gagnant[feature_columns],\n",
    "                                                     df_gagnant[response_column], test_size=0.25, random_state=42)\n",
    "train_eval_X =  df_gagnant[feature_columns]\n",
    "train_eval_Y=  df_gagnant[response_column]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Train_x\",train_x.shape)\n",
    "print(\"Train y\",train_y.shape)\n",
    "print(\"Test x\",test_x.shape)\n",
    "print(\"Test y\",test_y.shape)\n",
    "\n",
    "print(\"train_eval_X\",train_eval_X.shape)\n",
    "print(\"train_eval_Y\",train_eval_Y.shape)\n",
    "\n",
    "print(\"Test x\",test_x.shape)\n",
    "print(\"Test y\",test_y.shape)\n",
    "\n",
    "test_y = test_y['SELECTION'].ravel()\n",
    "train_y = train_y['SELECTION'].ravel()\n",
    "\n",
    "\n",
    "\n",
    "def smot2(train_x,train_y,feature_columns):\n",
    "    start_time=timer()\n",
    "    from imblearn.combine import SMOTEENN\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "    #print('\\nOriginal dataset shape {}'.format(Counter(train_y)))\n",
    "    sm = SMOTEENN(ratio='minority',n_jobs=3,random_state=42,\n",
    "                         n_neighbors=15,smote=SMOTE())\n",
    "    \n",
    "    sm = SMOTE(ratio='minority', n_jobs=3, random_state=42,m_neighbors=5)\n",
    "\n",
    "\n",
    "    X_res, y_res = sm.fit_sample(train_x, train_y)\n",
    "\n",
    "\n",
    "\n",
    "    train_x = pd.DataFrame(X_res, columns=feature_columns)\n",
    "    train_y = pd.Series(y_res)\n",
    "    print(\"Fin SMOT\")\n",
    "    timer(start_time)\n",
    "\n",
    "\n",
    "    return train_x,train_y\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silence_esti=False\n",
    "#train_x, train_y = smot2(train_x=train_x, train_y=train_y, feature_columns=feature_columns)\n",
    "#test_x, test_y = smot2(train_x=test_x, train_y=test_y, feature_columns=feature_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if allure_etudier == 1:\n",
    "                  estimator = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.6,\n",
    "       colsample_bytree=0.7, gamma=0.0, learning_rate=0.04,\n",
    "       max_delta_step=3, max_depth=11, max_features='sqrt',\n",
    "       min_child_weight=6, n_estimators=1800, n_jobs=2,\n",
    "       nthread=None, objective='binary:logistic', random_state=42,\n",
    "       reg_alpha=1e-05, reg_lambda=5.0, scale_pos_weight=1, seed=80,\n",
    "       silent=False, subsample=1)\n",
    "if allure_etudier == 3:\n",
    "                estimator = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                colsample_bytree=0.9, gamma=0.3, learning_rate=0.07,\n",
    "                max_delta_step=4, max_depth=10, max_features='sqrt',\n",
    "                min_child_weight=13, n_estimators=1800, n_jobs=1,\n",
    "                nthread=None, objective='binary:logistic', random_state=10,\n",
    "                reg_alpha=0.2, reg_lambda=1, scale_pos_weight=1, seed=400,\n",
    "                silent=True, subsample=0.9)\n",
    "\n",
    "if allure_etudier == 2:\n",
    "                estimator = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.5, gamma=0.2, learning_rate=0.07,\n",
    "       max_delta_step=8, max_depth=7, max_features='sqrt',\n",
    "       min_child_weight=2, n_estimators=2430, n_jobs=2,\n",
    "       nthread=None, objective='binary:logistic', random_state=10,\n",
    "       reg_alpha=1e-05, reg_lambda=3, scale_pos_weight=6, seed=1090,\n",
    "       silent=False, subsample=1)\n",
    "\n",
    "if allure_etudier == 4:\n",
    "                 estimator =  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                colsample_bytree=0.6, gamma=0.1, learning_rate=0.07,\n",
    "                max_delta_step=0, max_depth=9, max_features='sqrt',\n",
    "                min_child_weight=14, n_estimators=100, n_jobs=1,\n",
    "                nthread=None, objective='binary:logistic', random_state=10,\n",
    "                reg_alpha=0.03, reg_lambda=1, scale_pos_weight=1, seed=27,\n",
    "                silent=True, subsample=0.9)\n",
    "\n",
    "if allure_etudier == 5:\n",
    "                estimator = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                       colsample_bytree=0.6, gamma=0.1, learning_rate=0.07,\n",
    "                       max_delta_step=0, max_depth=9, max_features='sqrt',\n",
    "                       min_child_weight=12, n_estimators=100, n_jobs=1,\n",
    "                       nthread=None, objective='binary:logistic', random_state=10,\n",
    "                       reg_alpha=0.03, reg_lambda=1, scale_pos_weight=1, seed=27,\n",
    "                       silent=True, subsample=0.9)\n",
    "\n",
    "\n",
    "        \n",
    "model=estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=timer()\n",
    "eval_set = [(train_x, train_y), (test_x, test_y)]\n",
    "model.fit(train_x, train_y, eval_metric=[\"error\", \"auc\"], eval_set=eval_set, verbose=False, early_stopping_rounds=75)\n",
    "\n",
    "print(\"***********\")\n",
    "timer(start_time)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "PROBA = model.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # evaluate predictions\n",
    "accuracy = accuracy_score(test_y, predictions)\n",
    "print(\">>>>>>>>>>  Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(feature_columns=feature_columns,model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numero_a_predire = lecture_data('d:\\data_jour.csv', xnames, ['IDPARTCIPANT', 'IDCOURSE'],allure=allure_etudier,avec_index=False)\n",
    "print(\"Fichier lu d:\\data_jour.csv\" )\n",
    "\n",
    "df_numero_a_predire = df_numero_a_predire.groupby(\"ALLURE\")\n",
    "df_numero_a_predire = df_numero_a_predire.get_group(allure_etudier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_journee=calcul_les_notes(df_numero_a_predire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2_journee=conversion(df2_journee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2=transformation(df_numero_a_predire,allure_etudier)\n",
    "\n",
    "df2_journee = suppression_colonne(df2=df2_journee,allure=0)\n",
    "df2_journee = suppression_colonne(df2=df2_journee,allure=allure_etudier)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df_numero_a_predire=transformation_courses(df_numero_a_predire,allure_etudier)\n",
    "\n",
    "#df_numero_a_predire, critere_scale =encodage(df_numero_a_predire)\n",
    "\n",
    "\n",
    "\n",
    "#df_numero_a_predire =suppression_colonne(df_numero_a_predire, allure=0)\n",
    "#df_numero_a_predire =suppression_colonne(df_numero_a_predire, allure=allure_etudier)\n",
    "\n",
    "df2_journee['SELECTION'] = 0\n",
    "\n",
    "\n",
    "#print(df_numero_a_predire.info())\n",
    "print('\\n')\n",
    "print(feature_columns)\n",
    "print(\" \\n ------SUPPRESSIOOn OK------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_journee=df2_journee.set_index( ['IDPARTCIPANT', 'IDCOURSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_journee.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = split_dataset(df2_journee, 0, feature_columns, response_column)\n",
    "\n",
    "test_y = test_y['SELECTION'].ravel()\n",
    "\n",
    "\n",
    "y_pred = model.predict(test_x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame.from_dict(y_pred)\n",
    "\n",
    "test_copy = test_x.copy() #################\n",
    "\n",
    "PROBA = model.predict_proba(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proba = pd.DataFrame.from_dict(PROBA)    \n",
    "df_final = pd.concat([df_proba, df_pred], axis=1)\n",
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_x = test_copy.copy()\n",
    "\n",
    "test_x =my_drop(test_x, 'PAR_CLASSE_AGE')\n",
    "\n",
    "test_x =my_drop(test_x, 'PAR_ENT_ECART_GAGNANT')\n",
    "test_x =my_drop(test_x, 'PAR_ENT_RAPPORT_GAGNANT_M')\n",
    "test_x =my_drop(test_x, 'PAR_ENT_REU_PLACE')\n",
    "test_x =my_drop(test_x, 'PAR_ENT_REUSSITE_GAGNE')\n",
    "test_x =my_drop(test_x, 'PAR_ENT_VICTOIRE')\n",
    "test_x =my_drop(test_x, 'PAR_GAIN')\n",
    "test_x =my_drop(test_x, 'pAR_JOC_ECART_GAGNANT')\n",
    "test_x =my_drop(test_x, 'PAR_JOC_ECART_PLACE')\n",
    "test_x =my_drop(test_x, 'PAR_JOC_NB_COURSE')\n",
    "test_x =my_drop(test_x, 'PAR_JOC_PLACE_3P')\n",
    "test_x =my_drop(test_x, 'PAR_REUSSITE_GAGNE')\n",
    "test_x =my_drop(test_x, 'PAR_REUSSITE_QUINTE')\n",
    "test_x =my_drop(test_x, 'PAR_RUESSITE_PLACE')\n",
    "test_x =my_drop(test_x, 'CO_PRIX')\n",
    "test_x =my_drop(test_x, 'PAR_CARRIERE')\n",
    "test_x =my_drop(test_x, 'PAR_CARRIERE_Q')\n",
    "test_x =my_drop(test_x, 'pAR_JOC_RAPPORT_GAGNANT_M')\n",
    "test_x =my_drop(test_x, 'pAR_JOC_REUSSITE_GAGNE')\n",
    "test_x =my_drop(test_x, 'pAR_JOC_VICTOIRE')\n",
    "test_x =my_drop(test_x, 'PAR_PLACE')\n",
    "test_x =my_drop(test_x, 'PAR_PLACE_Q')\n",
    "test_x =my_drop(test_x, 'PAR_CLASSE_AGE')\n",
    "test_x =my_drop(test_x, 'pAR_JOC_VICTOIRE')\n",
    "test_x =my_drop(test_x, 'PAR_REUSSITE_3P')\n",
    "test_x =my_drop(test_x, 'PAR_JOC_REU_PLACE')\n",
    "test_x =my_drop(test_x, 'PAR_NUM')\n",
    "test_x =my_drop(test_x, 'PAR_COTEDER')\n",
    "test_x =my_drop(test_x, 'CORDE')\n",
    "test_x =my_drop(test_x, 'musique')\n",
    "test_x =my_drop(test_x, 'CHEVAL')\n",
    "test_x =my_drop(test_x, 'Nb_partant')\n",
    "\n",
    "test_x =my_drop(test_x, 'autostart')\n",
    "test_x =my_drop(test_x, 'grande_piste')\n",
    "test_x =my_drop(test_x, 'cendre')\n",
    "\n",
    "test_x =my_drop(test_x, 'PAR_PROPRIO')\n",
    "test_x =my_drop(test_x, 'NOM_JOC')\n",
    "test_x =my_drop(test_x, 'NOM_ENTR')\n",
    "\n",
    "test_x =my_drop(test_x, 'HIPPO')\n",
    "test_x =my_drop(test_x, 'PAR_AGE')\n",
    "test_x =my_drop(test_x, 'POIDS')\n",
    "test_x =my_drop(test_x, 'CO_DISTANCE')\n",
    "test_x =my_drop(test_x, 'CO_PRIX')\n",
    "test_x =my_drop(test_x, 'PAR_GAIN_NORMA')\n",
    "test_x =my_drop(test_x, 'CHEVAL2')\n",
    "test_x =my_drop(test_x, 'PAR_REUSSITE_3P2')\n",
    "test_x =my_drop(test_x, 'PAR_REUSSITE_QUINTE2')\n",
    "test_x =my_drop(test_x, 'PAR_CLASSE_AGE2')\n",
    "test_x =my_drop(test_x, 'PAR_COTEDER2')\n",
    "test_x =my_drop(test_x, 'Point')\n",
    "\n",
    "test_x =my_drop(test_x, 'MUSIC_CHEVAL')\n",
    "test_x =my_drop(test_x, 'MUSIC_ENT')\n",
    "test_x =my_drop(test_x, 'MUSIC_JOC')\n",
    "test_x =my_drop(test_x, 'PAR_VALEUR')\n",
    "\n",
    "test_x =my_drop(test_x, 'MY_REUSSITE_CHEVAL')\n",
    "test_x =my_drop(test_x, 'MY_REUSSITE_JOC')\n",
    "\n",
    "test_x =my_drop(test_x, 'MY_REUSSITE_ENT')\n",
    "test_x =my_drop(test_x, 'MY_ECART_JOC')\n",
    "test_x =my_drop(test_x, 'CLA_AGE_PRIX')\n",
    "test_x =my_drop(test_x, 'MY_auto_start')\n",
    "\n",
    "\n",
    "test_x =my_drop(test_x, 'PAR_ENT_ECART_PLACE')\n",
    "test_x =my_drop(test_x, 'PAR_VICTOIRE')\n",
    "test_x =my_drop(test_x, 'PAR_VICTOIRE_Q')\n",
    "test_x =my_drop(test_x, 'CHEVAL_QUINTE')\n",
    "test_x =my_drop(test_x, 'PAR_ENT_NB_COURSE')\n",
    "test_x =my_drop(test_x, 'p2018')\n",
    "\n",
    "\n",
    "test_x['v0'] = 0.0\n",
    "test_x['v1'] = 0.0\n",
    "test_x['sel'] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_x\n",
    "cumul = 1\n",
    "nb_rows = len(df_proba.index)\n",
    "print(\"nb_rows=\", nb_rows)\n",
    "print(\" FORMATION DU FICHIER ...\",allure_etudier)\n",
    "for i in range(0, nb_rows):\n",
    "        n = df_proba[0][i]\n",
    "        test_x['v0'][i] = n\n",
    "        \n",
    "        n = df_proba[1][i]\n",
    "        test_x['v1'][i] = n\n",
    "        \n",
    "\n",
    "\n",
    "timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n fin de copie sur Test_x\", test_x.head(10))\n",
    "\n",
    "if (allure_etudier == 1):\n",
    "    test_x.to_csv(\"d:\\py_resultat_trot.csv\")\n",
    "\n",
    "if (allure_etudier == 2):\n",
    "    test_x.to_csv(\"d:\\py_resultat_galop.csv\")\n",
    "\n",
    "if (allure_etudier == 3):\n",
    "    test_x.to_csv(\"d:\\py_resultat_trot_monte.csv\")\n",
    "\n",
    "if (allure_etudier == 4):\n",
    "    test_x.to_csv(\"d:\\py_resultat_haie.csv\")\n",
    "\n",
    "if (allure_etudier == 5):\n",
    "    test_x.to_csv(\"d:\\py_resultat_steeple.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
